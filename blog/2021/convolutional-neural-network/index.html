<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> convolutional neural network | Wonkwon Raymond Lee </title> <meta name="author" content="Wonkwon Raymond Lee"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://wonkwonlee.github.io/blog/2021/convolutional-neural-network/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Wonkwon</span> Raymond Lee </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">convolutional neural network</h1> <p class="post-meta"> Created in April 14, 2021 </p> <p class="post-tags"> <a href="/blog/2021"> <i class="fa-solid fa-calendar fa-sm"></i> 2021 </a>   ·   <a href="/blog/tag/study"> <i class="fa-solid fa-hashtag fa-sm"></i> study</a>   <a href="/blog/tag/note"> <i class="fa-solid fa-hashtag fa-sm"></i> note</a>   ·   <a href="/blog/category/bootcamp"> <i class="fa-solid fa-tag fa-sm"></i> bootcamp</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="합성곱-신경망-convolutional-neural-network">합성곱 신경망 Convolutional Neural Network</h1> <h2 id="cnn이란">CNN이란</h2> <p><img width="1105" alt="cnn" src="https://user-images.githubusercontent.com/28593767/114647239-b9167f00-9d17-11eb-85e4-63c3384a14ec.png"></p> <ul> <li>합성곱 신경망은 인간의 시각 체계처럼 이미지를 인식하는 신경망으로 이미지가 입력값인 분류 문제를 잘 다룬다.</li> <li>CNN에서는 <strong>컨볼루션 층(Convolutional Layers)</strong>, <strong>풀링 층(Pooling Layers)</strong>, <strong>완전 연결 계층</strong>이 등장한다. <ul> <li> <em>이미지는 각 픽셀이 인접한 픽셀과 강한 연관성</em>이 있기 때문에 <em>컨볼루션 층에서는 출력값이 입력값의 일부로부터만 영향을 받는 국소성(Local Connectivity)이 강한 처리가 수행</em>된다.</li> <li> <em>풀링 층은 인식하는 대상의 위치를 유연하게 처리할 수 있는 구조</em>로 구성되어 있다.</li> </ul> </li> </ul> <h2 id="cnn의-구조">CNN의 구조</h2> <ul> <li>합성곱 신경망은 이미치 처리에 알맞게 다층 퍼셉트론을 변형시킨 신경망으로 이미지 처리에 알맞게 고안된 합성곱 계층과 풀링 계층이 새로운 유형의 은닉 계층으로 이용된다.</li> <li>합성곱 계층은 다층 퍼셉트론의 완전 연결 계층에 비해 획기적으로 줄어든 수의 파라미터만을 가지며 풀링 계층은 아예 파라미터를 갖지 않는다. <ul> <li>다층 퍼셉트론 신경망의 은닉 계층은 완전 연결 계층이기 때문에 많은 수의 픽셀로 구성된 이미지 데이터의 경우 입력 벡터 크기가 커지면서 완전 연결 계층의 가중치 파라미터가 엄청난 크기를 갖게 된다.</li> <li>메모리 부담도 문제지만 많은 파라미터 탓에 학습이 느려지기 쉬우며 지나치게 많은 양의 데이터가 필요할 수 있다.</li> </ul> </li> <li>합성곱 신경망은 합성곱 계층이 갖는 <em>소수의 파라미터를 집중적으로 학습 시키는 방법으로 이미지 처리 분야에서의 학습 품질을 크게 향상</em>시켰다.</li> </ul> <p><img width="957" alt="cnn2" src="https://user-images.githubusercontent.com/28593767/114647247-bcaa0600-9d17-11eb-87fc-50126ad9eb44.png"></p> <ul> <li>CNN에는 컨볼루션 층, 풀링 층, 완전 연결 계층의 3개 층이 있다. <ul> <li>이미지는 컨볼루션 층으로 입력되고 컨볼루션 층과 풀링 층은 몇 번 반복된 후 완전 연결 계층으로 연결된다.</li> <li>완전 연결 계층도 몇 번 반복되고 최종 완전 연결 계층은 출력층이 된다.</li> </ul> </li> <li>컨볼루션 층에서는 <em>입력되는 이미지에 여러 개의 필터 처리가 적용되어 입력된 이미지는 필터 처리 후에 이미지의 특징을 나타내는 여러 개의 이미지로 변환</em>된다.</li> <li>풀링 층에서는 이미지의 특징을 잃어버리지 않도록 <em>이미지 크기가 축소</em>된다.</li> <li>완전 연결 계층에서는 층 간의 모든 뉴런이 연결되어 있다.</li> </ul> <h3 id="컨볼루션-층-convolutional-layers">컨볼루션 층 Convolutional Layers</h3> <p><img width="1274" alt="convolution" src="https://user-images.githubusercontent.com/28593767/114647375-f7ac3980-9d17-11eb-87bd-25c67be91ff4.png"></p> <ul> <li>컨볼루션(합성곱)은 이미지 처리 분야에서 매우 일반적인 연산으로 이미지의 특징을 강화하거나 약화시킨다. <ul> <li>컨볼루션 층은 이 컨볼루션 연산을 통해 입력 이미지의 특징을 더 강조한 이미지로 변환한다.</li> </ul> </li> <li>이미지에는 각 픽셀이 인접하는 픽셀과 강한 관련성을 갖고 있는 성질이 있는데 이를 <strong>국소성(Locality)</strong> 혹은 집약성이라고 한다.</li> <li> <em>컨볼루션 층은 이러한 이미지의 국소성을 이용해 이미지의 특징을 검출</em>한다.</li> </ul> <p><img width="1287" alt="conv2" src="https://user-images.githubusercontent.com/28593767/114647379-f8dd6680-9d17-11eb-80c1-ed24b99a5494.png"></p> <ul> <li>일반적인 이미지 데이터는 각 픽셀이 RGB의 3색, 즉 3개의 채널을 갖고 있다.</li> <li>CNN은 여러 개의 채널을 가진 이미지에 대해 여러 개의 채널을 이용한 컨볼루션을 적용한다.</li> <li>각 필터는 입력 이미지와 같은 채널 수를 갖기 때문에, 예를 들어 입력 이미지가 RGB이면 각 필터에는 3개의 채널 수가 필요하다.</li> <li>컨볼루션에 의해 생성된 이미지의 각 픽셀에는 편향을 더해 활성화 함수에서 처리한다. <ul> <li>편향은 하나의 필터당 하나의 값을 설정하고 따라서 필터의 수와 편향의 수가 같다.</li> </ul> </li> </ul> <p><img width="830" alt="conv_full" src="https://user-images.githubusercontent.com/28593767/114647382-f975fd00-9d17-11eb-85de-6aa395e43b6f.png"></p> <ul> <li>컨볼루션 층은 필터마다 처리를 수행하기 때문에 완전 연결 계층과 비교해 층 간의 접속이 국소적이다.</li> <li>즉, 시각 영역과 같이 국소적인 특징을 파악하는 데 적합한 신경망 구조라고 할 수 있다.</li> <li>필터를 적용한 이미지 영역은 1차 시각 영역에서 단순형 세포의 수용 영역에 해당한다.</li> </ul> <h3 id="풀링-층-pooling-layers">풀링 층 Pooling Layers</h3> <p><img width="578" alt="pooling" src="https://user-images.githubusercontent.com/28593767/114647571-478b0080-9d18-11eb-9287-3519dc9ddb93.png"></p> <ul> <li>풀링 층은 보통 <em>컨볼루션층 바로 뒤에 배치되어 이미지를 여러 영역으로 구획하고 각 영역을 대표하는 값을 추출해 새로운 이미지</em>를 만드는데 이와 같은 처리를 <strong>풀링(Pooling)</strong> 이라고 한다.</li> <li>일반적으로 풀링은 <em>각 영역의 최댓값을 영역의 대표값으로 설정</em>하는데 이와 같은 풀링 방법을 <strong>맥스 풀링</strong>이라고 한다. <ul> <li>영역의 평균 값을 선택하는 평균 풀링 등의 방법도 있지만 CNN에서는 맥스 풀링이 많이 사용된다.</li> </ul> </li> <li>풀링 처리를 하면 이미지가 축소되고 이미지를 흐릿하게 처리하기 때문에 대상의 위치 감도가 저하된다. <ul> <li>풀링은 위치의 변화에 대해 강건성을 부여한다.</li> <li>또한 풀링을 통해 이미지의 크기가 축소되기 때문에 계산량이 감소하는 효과도 있다.</li> <li>풀링 층에서 <em>구획되는 영역은 고정되어 있고 학습하는 파라미터가 없으므로 학습이 진행되지 않고 채널이 합류되거나 분기되는 것도 없기 때문에 입력 채널 수와 출력 채널 수는 동일</em>하다.</li> </ul> </li> </ul> <h3 id="완전-연결-계층-fully-connected-layers">완전 연결 계층 Fully-Connected Layers</h3> <ul> <li>완전 연결 계층은 일반적인 신경망에서 이용되는 층으로 컨볼루션층과 풀링층이 몇 번 반복된 후 배치된다.</li> <li>컨볼루션 층과 풀링 층에서 추출된 특징량에 기반해 계산이 수행되고 결과를 출력한다.</li> <li>완전 연결 계층 사이의 연결에서는 일반적인 신경망과 마찬가지로 뉴런이 서로 이웃하는 층의 모든 뉴런과 연결된다. <ul> <li>컨볼루션 층과 풀링 층의 출력을 완전 연결 계층으로 입력할 경우 이미지를 벡터로 변환한다.</li> <li>예를 들어 출력 이미지의 높이가 H, 너비가 W, 채널 수가 F이면 완전 연결 계층의 입력은 크기가 H _ W _ F인 벡터가 된다.</li> </ul> </li> </ul> <h3 id="패딩-padding">패딩 Padding</h3> <p><img width="1275" alt="padding" src="https://user-images.githubusercontent.com/28593767/114647577-4954c400-9d18-11eb-96e0-930701b32ca7.png"></p> <ul> <li>컨볼루션 층과 풀링 층에서 <em>입력 이미지를 둘러싸는 것처럼 픽셀을 배치하는 기법</em>을 패딩이라고 한다.</li> <li>이미지의 주위에 값이 0인 픽셀을 배치하는 방법을 <strong>제로 패딩(Zero Padding)</strong> 이라고 한다.</li> <li>컨볼루션 층이나 풀링 층을 거치면 이미지 크기가 축소되지만 패딩을 적용하면 컨볼루션 처리를 거쳐도 이미지 크기가 변하지 않을 수 있다.</li> <li>또한 컨볼루션의 특성 상 이미지의 가장자리는 컨볼루션 적용 횟수가 적어지지만 패딩을 적용하면 가장자리 데이터에 적용되는 컨볼루션 횟수를 증가시켜 가장자리 부분의 특징도 포함시키는 장점이 있다.</li> </ul> <h3 id="스트라이드-stride">스트라이드 Stride</h3> <ul> <li>스트라이드는 <em>컨볼루션에서 필터가 이동하는 간격</em>을 의미한다.</li> <li>스트라이드가 커지면 필터의 이동 간격도 커지기 때문에 생성되는 이미지의 크기가 작아진다.</li> <li>매우 큰 이미지를 축소시키기 위해 스트라이드를 사용하기도 하지만 특징을 잘 포착하지 못할 우려가 있어 보통은 스트라이드를 1로 설정하는 편이 바람직하다.</li> </ul> <h3 id="cnn의-학습">CNN의 학습</h3> <ul> <li>CNN 역시 일반적인 신경망과 같이 역전파를 통해 학습이 수행된다.</li> <li>컨볼루션 층에서는 필터가 학습에 의해 최적화된다.</li> <li>출력값과 정답의 오차로부터 전파되어 온 값을 이용해 필터를 구성하는 각 값의 기울기를 계산하고 필터가 수정된다.</li> <li>편향 또한 같은 과정으로 수정되고 오차는 컨볼루션 층을 통해 더 앞 층으로 전파된다.</li> <li>완전 연결 계층에서는 일반적인 신경망과 같은 방법으로 오차의 전파가 진행된다.</li> </ul> <p><img width="543" alt="train" src="https://user-images.githubusercontent.com/28593767/114647580-4a85f100-9d18-11eb-9159-a797ccebf5a7.png"></p> <h3 id="채널-channel">채널 Channel</h3> <p><img width="827" alt="channel" src="https://user-images.githubusercontent.com/28593767/114651160-62607380-9d1e-11eb-8899-668b17547ce1.png"></p> <ul> <li>합성곱 연산에서 <em>커널은 입력 영역의 특정 패턴이나 특징에 민감하게 반응하는 방향으로 학습되는 경향</em>이 있고 따라서 합성곱 계층에서 출력되는 픽셀 이미지를 <strong>특징맵(Feature Map)</strong> 이라고 한다.</li> <li>CNN이 다루는 이미지 데이터에는 가로와 세로 해상도 외에 <strong>채널(Channel)</strong> 이라는 차원이 추가된다.</li> <li>합성곱 계층의 입력 채널 수는 최초의 입력 이미지 혹은 이전 계층이 생성한 출력 채널 수로 정해지지만, 출력 채널 수는 신경망 설계자가 마음대로 정할 수 있다. <ul> <li>일반적으로 합성곱 신경망을 설계할 때는 합성곱 계층의 출력 채널 수를 입력 채널 수보다 늘려 더 많은 종류의 특징을 파악할 수 있게 한다.</li> <li>이렇게 합성곱 계층을 거칠 때마다 늘어난 정보량은 합성곱 계층 사이에 배치된 풀링 계층을 통해 다시 줄어든다.</li> </ul> </li> <li>풀링 층을 거친 이미지는 대개 해상도가 줄어들기만 할 뿐 채널 수는 변하지 않고 그대로 유지된다.</li> </ul> <h3 id="커널-kernel">커널 Kernel</h3> <p><img width="446" alt="kernel" src="https://user-images.githubusercontent.com/28593767/114651157-6096b000-9d1e-11eb-8ac8-60d01957c7de.png"></p> <ul> <li>이미지의 작은 사각 영역에서 하나의 특징을 온전히 포착하려면 커널은 <em>해당 영역의 모든 채널에 대한 입력 픽셀값을 볼 수 있어야 한다</em>.</li> <li>하나의 특징을 포착하는 커널은 <em>사각 영역 입력의 모든 채널을 처리하는 3차원 가중치</em>를 가져야 한다.</li> <li>또한 출력 채널 수 만큼의 특징 맵을 만들어 내기 위해 커널이 출력 채널 수 만큼 있어야 한다.</li> <li>따라서 커널은 입력 영역 크기에 <em>입력 채널과 출력 채널이 모두 반영된 4차원 구조</em>가 되어야 한다.</li> </ul> <p><img width="638" alt="channel2" src="https://user-images.githubusercontent.com/28593767/114651561-2f6aaf80-9d1f-11eb-895c-0819c717851f.png"></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/mapping-the-mind-of-a-large-language-model-anthropic/">Mapping the Mind of a Large Language Model \ Anthropic</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/generative-adversarial-network/">generative adversarial network</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/reinforcement-learning/">reinforcement learning</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/database/">database</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/natural-language-processing/">natural language processing</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Wonkwon Raymond Lee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"publications in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A collection of my projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-repositories",title:"repositories",description:"A brief showcase of my repositories.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"cv",description:"Professional Curriculum Vitae",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"dropdown-publications",title:"publications",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-projects",title:"projects",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-blog",title:"blog",description:"",section:"Dropdown",handler:()=>{window.location.href="/blog/"}},{id:"post-mapping-the-mind-of-a-large-language-model-anthropic",title:'Mapping the Mind of a Large Language Model  Anthropic <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We have identified how millions of concepts are represented inside Claude Sonnet, one of our deployed large language models. This is the first ever detailed look inside a modern, production-grade large language model.",section:"Posts",handler:()=>{window.open("https://www.anthropic.com/research/mapping-mind-language-model","_blank")}},{id:"post-generative-adversarial-network",title:"generative adversarial network",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/generative-adversarial-network/"}},{id:"post-reinforcement-learning",title:"reinforcement learning",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/reinforcement-learning/"}},{id:"post-database",title:"database",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/database/"}},{id:"post-natural-language-processing",title:"natural language processing",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/natural-language-processing/"}},{id:"post-recurrent-neural-network",title:"recurrent neural network",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/recurrent-neural-network/"}},{id:"post-convolutional-neural-network",title:"convolutional neural network",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/convolutional-neural-network/"}},{id:"post-linear-algebra",title:"linear algebra",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/linear-algebra/"}},{id:"post-adaptive-moments-estimation",title:"adaptive moments estimation",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/adaptive-moments-estimation/"}},{id:"post-shortest-path-algorithm",title:"shortest path algorithm",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/shortest-path-algorithm/"}},{id:"post-dynamic-programming",title:"dynamic programming",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/dynamic-programming/"}},{id:"post-search-algorithm",title:"search algorithm",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/search-algorithm/"}},{id:"post-multi-layer-perceptron",title:"multi layer perceptron",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/multi-layer-perceptron/"}},{id:"post-classification",title:"classification",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/classification/"}},{id:"post-tree",title:"tree",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/tree/"}},{id:"post-sorting-algorithm",title:"sorting algorithm",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/sorting-algorithm/"}},{id:"post-regression-analysis",title:"regression analysis",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/regression-analysis/"}},{id:"post-stack-and-queue",title:"stack and queue",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/stack-and-queue/"}},{id:"post-jupyter-and-markdown",title:"jupyter and markdown",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/jupyter-and-markdown/"}},{id:"post-dfs-and-bfs",title:"dfs and bfs",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/dfs-and-bfs/"}},{id:"post-single-layer-perceptron",title:"single layer perceptron",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/single-layer-perceptron/"}},{id:"post-linear-regression",title:"linear regression",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/linear-regression/"}},{id:"post-foundations-of-mathematics",title:"foundations of mathematics",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/foundations-of-mathematics/"}},{id:"post-foundations-of-artificial-intelligence",title:"foundations of artificial intelligence",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/foundations-of-artificial-intelligence/"}},{id:"post-differential",title:"differential",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/differential/"}},{id:"post-complexity",title:"complexity",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2021/complexity/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-out-of-distribution-robustness-evaluation-of-state-of-the-art-vision-models",title:"Out-of-distribution Robustness Evaluation of State-of-the-art Vision Models",description:"Research project comparing the robustness of 58 computer vision models",section:"Projects",handler:()=>{window.location.href="/projects/1_ood/"}},{id:"projects-time-series-medical-image-classification",title:"Time-series Medical Image Classification",description:"Image Classification Model for Temporal Disease Progression of Chest X-ray dataset",section:"Projects",handler:()=>{window.location.href="/projects/2_timeseries_medical/"}},{id:"projects-epistemic-parity-reproducibility-as-an-evaluation-metric-for-differential-privacy",title:"Epistemic Parity: Reproducibility as an Evaluation Metric for Differential Privacy",description:"A benchmark and evaluation for reproducibility in differential privacy with state-of-the-art DP synthesizers.",section:"Projects",handler:()=>{window.location.href="/projects/3_synrd/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%77%6F%6E%6B%77%6F%6E.%6C%65%65@%6E%79%75.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=xXZLYFwAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/wonkwonlee","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/wonkwon-lee","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>