<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://wonkwonlee.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://wonkwonlee.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-09-13T04:20:47+00:00</updated><id>https://wonkwonlee.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Mapping the Mind of a Large Language Model \ Anthropic</title><link href="https://wonkwonlee.github.io/blog/2024/mapping-the-mind-of-a-large-language-model-anthropic/" rel="alternate" type="text/html" title="Mapping the Mind of a Large Language Model \ Anthropic"/><published>2024-05-21T00:00:00+00:00</published><updated>2024-05-21T00:00:00+00:00</updated><id>https://wonkwonlee.github.io/blog/2024/mapping-the-mind-of-a-large-language-model--anthropic</id><content type="html" xml:base="https://wonkwonlee.github.io/blog/2024/mapping-the-mind-of-a-large-language-model-anthropic/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[We have identified how millions of concepts are represented inside Claude Sonnet, one of our deployed large language models. This is the first ever detailed look inside a modern, production-grade large language model.]]></summary></entry><entry><title type="html">generative adversarial network</title><link href="https://wonkwonlee.github.io/blog/2021/generative-adversarial-network/" rel="alternate" type="text/html" title="generative adversarial network"/><published>2021-05-24T00:00:00+00:00</published><updated>2021-05-24T00:00:00+00:00</updated><id>https://wonkwonlee.github.io/blog/2021/generative-adversarial-network</id><content type="html" xml:base="https://wonkwonlee.github.io/blog/2021/generative-adversarial-network/"><![CDATA[<h1 id="gan-generative-adversarial-network">GAN Generative Adversarial Network</h1> <h2 id="turing-test">Turing Test</h2> <blockquote> <p><em>기계는 사고할 수 있을까?</em> 엘런 튜링은 그의 논문 “<strong>computing machinery and intelligence</strong>” 에서 오늘날 튜링 테스트라고 알려진 이미테이션 게임이라는 실험을 제안했다.</p> </blockquote> <ul> <li>머신러닝 알고리즘은 이미 존재하는 데이터에서 패턴을 인식하고 그 통찰을 사용하여 분류나 회귀와 같은 작업을 처리 하는 데 뛰어나지만 <em>컴퓨터가 새로운 데이터를 생성하는 것</em>은 쉽지 않다.</li> <li>2014년 몬트리올 대학교의 이언 굿펠로(Ian Goodfellow)가 GAN을 발명한 이후 상황이 바뀌게 되었다.</li> <li>GAN은 신경망 하나가 아닌 <em>두 개의 구분된 신경망을 이용해 실제와 유사한 데이터를 생성</em>한다.</li> <li>이를 통해 레이블된 훈련 데이터를 대량으로 준비하지 않은 상태로 진짜 같은 품질의 가짜 이미지를 생성하거나, 낙서를 사진 같은 이미지로 만들거나, 말 영상을 달리는 얼룩말 영상으로 만들 수 있게 되었다.</li> </ul> <h2 id="생성적-적대-신경망-gan">생성적 적대 신경망 GAN</h2> <p><img width="1005" alt="gan" src="https://user-images.githubusercontent.com/28593767/116950074-f3dc5900-acbe-11eb-986b-dddb5bc6b4c5.png"/></p> <ul> <li>GAN은 <strong>생성적 적대 신경망(Generative Adversarial Network)</strong> 의 약자로 동시에 두 개의 모델을 훈련하는 머신러닝의 한 종류이다. <ul> <li><strong>생성자(Generator)</strong> 는 가짜 데이터를 생성하도록 훈련되고 <strong>판별자(Discriminator)</strong> 는 실제 샘플과 가짜 샘플을 구분하도록 훈련한다.</li> </ul> </li> <li><strong>생성적(Generative)</strong> 라는 용어는 <em>새로운 데이터를 생성한다는 이 모델의 목적</em>을 나타낸다. <ul> <li>GAN이 생성하기 위해 학습할 데이터는 훈련 데이터셋에 따라 결정된다.</li> <li>예를 들어 GAN을 이용해 레오나르도 다빈치의 작품처럼 보이는 이미지를 만들고 싶다면 다빈치의 작품을 훈련 데이터셋으로 사용하면 된다.</li> </ul> </li> <li><strong>적대적(Adversarial)</strong> 이라는 용어는 <em>GAN의 뼈대를 이루는 두 모델인 생성자와 판별자 사이의 게임 같은 경쟁 구도</em>를 나타낸다. <ul> <li><em>생성자의 목표는 훈련 데이터셋에 있는 실제 데이터와 구분이 안될 정도로 유사한 샘플을 만드는 것이고 판별자의 목표는 생성자가 만든 가짜 데이터를 훈련 데이터셋에 있는 실제 데이터와 구별하는 것</em>이다.</li> <li>예를 들어 생성자는 다빈치의 그림처럼 보이는 그림을 생성하고 판별자는 다빈치의 것으로 보이는 그림이 진짜인지 조사한다.</li> </ul> </li> <li><em>생성자와 판별자는 서로를 이기려는 경쟁을 지속</em>하고 생성자가 더 그럴듯한 데이터를 생성할수록 판별자 역시 가짜와 진짜를 구별하는 일에 탁월해져야 한다.</li> </ul> <p><img width="1172" alt="gan2" src="https://user-images.githubusercontent.com/28593767/116950078-f8a10d00-acbe-11eb-8b1a-327dc519e322.png"/></p> <ul> <li>생성자의 목표는 훈련 데이터와 구별이 안 될 정도로 훈련 데이터셋의 특징이 잘 나타난 샘플을 생성하는 것이다. <ul> <li>객체 탐지 모델과는 반대로 패턴을 인식하는 대신 이미지를 직접 처음부터 만들도록 학습한다.</li> <li>생성자는 판별자의 분류 결과에서 피드백을 받아 학습을 계속한다.</li> </ul> </li> <li>판별자의 목표는 특정 샘플이 진짜(훈련 데이터)인지 가짜(생성자가 생성한 데이터)인지 구별하는 것이다. <ul> <li>판별자가 가짜를 진짜로 분류할 때마다 생성자는 자신이 임무를 잘 수행하고 있다는 것을 피드백 받고 생성자가 만든 이미지가 가짜라는 걸 판별자가 포착할 때마다 생성자는 더 그럴듯한 결과물을 생성해야 한다는 피드백을 받는다.</li> </ul> </li> </ul> <h3 id="gan의-구조">GAN의 구조</h3> <p><img width="1005" alt="gan3" src="https://user-images.githubusercontent.com/28593767/116950079-f939a380-acbe-11eb-8390-48c160b4fbd2.png"/></p> <ol> <li>훈련 데이터셋 <ul> <li>생성자가 거의 완벽한 수준으로 모방하기 위해 학습하는 진짜 샘플 데이터셋이다.</li> <li>데이터셋은 <em>판별자 신경망의 입력(x)</em> 으로 제공된다.</li> </ul> </li> <li>랜덤한 잡음 벡터 <ul> <li>랜덤한 숫자 벡터로 생성자가 <em>가짜 샘플 합성의 시작점</em>으로 사용한다.</li> <li><em>생성자 신경망의 입력(z)</em> 으로 제공된다.</li> </ul> </li> <li>생성자 신경망 <ul> <li>생성자는 <em>랜덤한 숫자 벡터(z)를 입력으로 받아서 가짜 샘플(x’)을 출력</em>한다.</li> <li>생성자의 목표는 훈련 데이터셋의 진짜 샘플과 구별이 안 되는 가짜 샘플을 생성하는 것이다.</li> </ul> </li> <li>판별자 신경망 <ul> <li>판별자는 <em>훈련 데이터셋의 진짜 샘플(x)과 생성자가 만든 가짜 샘플(x’)을 입력</em>으로 받는다.</li> <li>판별자는 각 <em>샘플이 진짜일 확률을 계산</em>해 출력한다.</li> </ul> </li> <li>반복 훈련 <ul> <li>판별자의 예측이 얼마나 정확한지 평가하여 역전파로 판별자와 생성자 신경망을 반복해서 훈련한다.</li> <li>판별자의 가중치와 편향은 <em>분류 정확도를 최대화 하도록 업데이트</em>된다. <ul> <li><em>x를 진짜로 판단하고 x’을 가짜로 판단하도록</em> 올바른 예측의 확률을 최대화 한다.</li> </ul> </li> <li>생성자의 가중치와 편향은 <em>판별자가 x’을 진짜로 잘못 분류할 확률을 최대화 하도록 업데이트</em>된다.</li> </ul> </li> </ol> <h3 id="gan-훈련-알고리즘">GAN 훈련 알고리즘</h3> <p>매 훈련 반복에서 다음 과정을 반복한다.</p> <ol> <li><strong>판별자 훈련하기</strong> <ul> <li><img width="630" alt="gen" src="https://user-images.githubusercontent.com/28593767/116950243-63524880-acbf-11eb-9176-06c07fbbbc3d.png"/></li> <li>훈련 데이터셋에서 랜덤하게 진짜 샘플 x를 선택</li> <li>새로운 랜덤한 잡음 벡터 z를 얻어서 생성자 네트워크를 이용해 가짜 샘플 x’을 합성</li> <li>판별자 신경망을 이용해 x와 x’을 분류</li> <li><em>분류 오차를 계산하고 전체 오차를 역전파해서 판별자의 훈련 가능한 파라미터를 업데이트하고 분류 오차를 최소화</em></li> </ul> </li> <li><strong>생성자 훈련하기</strong> <ul> <li><img width="630" alt="dis" src="https://user-images.githubusercontent.com/28593767/116950249-65b4a280-acbf-11eb-92e3-91a2c4a64b2a.png"/></li> <li>생성자 신경망을 사용해 새로운 랜덤한 잡음 벡터 z에서 가짜 샘플 x’을 합성</li> <li>판별자 신경망을 이용해 x’을 분류</li> <li><em>분류 오차를 계산하고 역전파해서 생성자의 훈련 가능한 파라미터를 업데이트하고 판별자의 오차를 최대화</em></li> </ul> </li> <li><strong>균형에 도달하기</strong> <ul> <li><img width="983" alt="eq" src="https://user-images.githubusercontent.com/28593767/116950252-664d3900-acbf-11eb-9058-47b323f5dedd.png"/></li> <li>GAN 훈련 반복은 <strong>내쉬 균형(Nash Equilibrium)</strong> 에 도달할 때까지 반복된다.</li> <li>가짜 샘플이 훈련 데이터셋의 진짜 샘플과 구별이 안된다면 <em>판별자가 이 둘을 분간할 방법은 전혀 없고 50% 확률로 진짜 혹은 가짜로 분류하는 게 판별자가 할 수 있는 최선</em>이다.</li> <li>생성자가 만드는 가짜 샘플이 이미 진짜 샘플과 구분이 안될 때 <em>변환하는 과정을 약간만 바꾸더라도 판별자에게 가짜 샘플과 진짜 샘플을 구별할 수 있는 실마리를 제공하고 생성자의 성능은 오히려 나빠진다</em>.</li> <li>균형에 도달하면 GAN은 <strong>수렴(Converged)</strong> 했다고 말한다. <ul> <li>실무에서는 <strong>비볼록 게임(Nonconvex Game)</strong> 의 수렴 도달에는 복잡성이 매우 크기 때문에 GAN의 내시 균형을 찾기가 불가능에 가깝다.</li> </ul> </li> </ul> </li> </ol> <h2 id="오토인코더-autoencoder">오토인코더 AutoEncoder</h2> <h3 id="오토인코더의-구조">오토인코더의 구조</h3> <p><img width="786" alt="auto" src="https://user-images.githubusercontent.com/28593767/116952122-d9a57980-acc4-11eb-8309-d7c53a5f611b.png"/></p> <ul> <li><strong>1 단계: 인코더 신경망</strong> <ul> <li>학습된 인코더(다층 신경망)를 사용해 표현 x(예를 들어 이미지)의 차원을 y에서 z로 낮춘다.</li> </ul> </li> <li><strong>2단계: 잠재공간 z</strong> <ul> <li>훈련을 함에 따라 <em>잠재 공간이 어떠한 의미를 가지도록 구성</em>된다.</li> <li><em>잠재 공간은 보통 작은 차원으로 표현</em> 되며 중간 단계의 역할을 한다.</li> <li>여기서 만든 데이터의 표현으로 오토인코더가 <em>생각을 체계화</em>한다.</li> </ul> </li> <li><strong>3 단계: 디코더 신경망</strong> <ul> <li><em>디코더를 이용해 입력 객체를 원본 차원으로 재구성</em>한다.</li> <li>일반적으로 인코더를 거꾸로 뒤집은 신경망으로 구성한다.</li> </ul> </li> <li>재구성 손실을 최소화하는 인코더와 디코더의 파라미터를 경사하강법으로 업데이트하여 최적의 값을 찾는다.</li> </ul>]]></content><author><name></name></author><category term="bootcamp"/><category term="study"/><category term="note"/><summary type="html"><![CDATA[GAN Generative Adversarial Network]]></summary></entry><entry><title type="html">reinforcement learning</title><link href="https://wonkwonlee.github.io/blog/2021/reinforcement-learning/" rel="alternate" type="text/html" title="reinforcement learning"/><published>2021-05-03T00:00:00+00:00</published><updated>2021-05-03T00:00:00+00:00</updated><id>https://wonkwonlee.github.io/blog/2021/reinforcement-learning</id><content type="html" xml:base="https://wonkwonlee.github.io/blog/2021/reinforcement-learning/"><![CDATA[<h1 id="강화-학습-reinforcement-learning">강화 학습 Reinforcement Learning</h1> <h2 id="강화-학습의-정의-definition-of-rl">강화 학습의 정의 Definition of RL</h2> <ul> <li>강화 학습이란 쉽게 말해서 <em><strong>시행 착오(Trial and Error)</strong> 를 통해 발전해 나가는 과정</em>이라고 할 수 있다.</li> <li>즉, 강화 학습이란 <em><strong>순차적 의사결정(Sequential Decision Making)</strong> 문제에서 누적 보상을 최대화 하기 위해 시행 착오를 통해 행동을 교정하는 학습 과정</em>이라고 정의할 수 있다.</li> </ul> <h2 id="순차적-의사결정-sequential-decision-making">순차적 의사결정 Sequential Decision Making</h2> <ul> <li>순차적 의사결정 문제란 각 상황에 따라 하는 행동이 다음 상황에 영향을 주며 결국 연이은 행동을 잘 선택해야 하는 문제를 의미한다.</li> <li>즉, 강화 학습은 이러한 중요한 문제를 풀기 위해 고안된 방법론이라고 할 수 있다.</li> </ul> <h2 id="보상-reward">보상 Reward</h2> <ul> <li>보상이란 의사결정을 얼마나 잘하고 있는지 알려주는 신호이다.</li> <li>강화 학습의 목적은 과정에서 받는 보상의 총합, 즉 <strong>누적 보상(Cumulative Reward)</strong> 을 최대화 하는 것이라고 할 수 있다.</li> <li>보상의 3가지 특성: <strong><em>어떻게가 아닌 얼마나, 스칼라, 희소하고 지연된 보상</em></strong></li> </ul> <ol> <li><strong>어떻게 X 얼마나 O</strong> <ul> <li>보상의 <em>첫 번째 특징은 보상은 어떻게에 대한 정보를 담고 있지 않다는 점</em>이다.</li> <li>보상은 내가 어떤 행동을 하면 그것에 대해 <em>단순히 얼마나 잘 하고 있는지 평가 해줄 뿐, 어떻게 해야 높은 보상을 얻을 수 있을지 알려주지 않는다</em>.</li> <li>다시 말해, 보상은 지도 학습의 정답과 질적으로 다르다.</li> <li>보상은 어떻게 해야 할지를 직접적으로 알려주지는 않지만, 사후적으로 보상이 낮았던 행동들은 덜 하고, 보상이 높았던 행동들은 더 하면서 보상을 최대화 하도록 행동을 조금씩 수정해 나간다.</li> </ul> </li> <li><strong>스칼라</strong> <ul> <li>보상의 두 번째 특징은 보상이 <strong>스칼라(Scalar)</strong> 라는 점이다.</li> <li>스칼라는 <strong>벡터(Vector)</strong> 와는 다르게 크기를 나타내는 값 하나로 이루어져 있다. <ul> <li><em>보상이 벡터라면 동시에 2개 이상의 값을 목표로 할 수 있겠지만 스칼라이기 때문에 오직 하나의 목적만을 가져야 한다</em>.</li> </ul> </li> <li>강화 학습은 스칼라 형태의 보상이 있는 경우에만 적용할 수 있다. <ul> <li>만일 어떤 문제가 하나의 목표만을 설정하기 어렵다면 문제를 단순화하여 하나의 목표를 설정해야 한다.</li> <li>반대로 잘 정해진 하나의 숫자로 된 목표가 있다면 강화 학습은 해당 목표를 최대로 취하도록 최적화한다.</li> </ul> </li> </ul> </li> <li><strong>희소하고 지연된 보상</strong> <ul> <li>보상의 세 번째 특징은 보상이 <strong>희소(Sparse)</strong> 할 수 있으며 또 <strong>지연(Delay)</strong> 될 수 있다는 점이다.</li> <li>행동과 보상이 일대일로 대응이 된다면 행동에 대한 평가가 즉각적으로 이루어지는 만큼 강화 학습이 한결 쉬워진다.</li> <li>하지만 <em>보상은 선택했던 행동의 빈도에 비해 훨씬 가끔 주어지거나, 행동이 발생한 후 한참 뒤에 나올 수 있고 이 때문에 행동과 보상의 연결이 어려워 진다.</em></li> <li>다시 말해, <em>보상이 어떤 행동 덕분인지 책임 소재가 불분명하기 때문에 그만큼 학습 난이도가 높다</em>.</li> <li>보상이 희소할수록 학습이 어려워지고 이러한 문제를 해결하기 위해 최근 강화 학습 연구에서는 <strong>밸류 네트워크(Value Network)</strong> 등의 아이디어가 등장했다.</li> <li>이러한 특성은 <em>지도 학습과 강화 학습을 본질적으로 다르게 만드는 요소</em>라고 할 수 있다. <ul> <li>지도 학습에서는 정답이 뒤늦게 주어지는 경우는 없고 오직 데이터와 정답의 쌍이 존재한다.</li> <li>반면 강화 학습에서 다루는 문제는 순차적 의사결정 문제이므로 시간에 따른 흐름이 중요하고 이 흐름에서 보상이 뒤늦게 주어질 수 있다.</li> </ul> </li> </ul> </li> </ol> <h2 id="순차적-행동-결정문제-markov-decision-process">순차적 행동 결정문제 Markov Decision Process</h2> <ol> <li><strong>상태 State</strong> <ul> <li><em>에이전트의 상태로서 공학에서 많이 사용하는 개념</em>으로 정적인 요소 뿐 아니라 동적인 요소 또한 상태로 표현할 수 있다.</li> <li>에이전트가 <em>상태를 통해 상황을 판단해서 행동을 결정해야 하기에 에이전트에게 충분한 정보를 제공해야</em> 하므로 엄밀히 말하면 상태보다는 관찰이라는 것이 정확한 표현이라고 할 수 있다.</li> </ul> </li> <li><strong>행동 Action</strong> <ul> <li>에이전트가 어떠한 상태에서 취할 수 있는 행동으로 [상, 하, 좌, 우]와 같은 것을 말한다.</li> <li><em>학습이 되지 않은 에이전트는 어떤 행동이 좋은 행동인지에 대한 정보가 전혀 없으므로 처음에는 무작위로 행동</em>을 취할 수 밖에 없다.</li> <li>하지만 에이전트는 학습하면서 <em>특정한 행동들을 할 확률을 높이고 에이전트가 행동을 취하면 환경은 에이전트에게 보상을 주고 다음 상태를 알려준다</em>.</li> </ul> </li> <li><strong>보상 Reward</strong> <ul> <li>보상은 강화학습을 다른 머신러닝 기법과 다르게 만들어 주는 가장 핵심적인 요소이다.</li> <li>보상이라는 정보를 통해 에이전트는 자신이 했던 행동들을 평가할 수 있고 이로 인해 어떤 행동이 좋은 행동인지 알 수 있다.</li> <li>강화 학습의 목표는 시간에 따라 얻는 보상들의 합을 최대로 하는 정책을 찾는 것이다.</li> </ul> </li> <li><strong>정책 Policy</strong> <ul> <li><em>순차적 행동 결정문제에서 구해야 할 답은 바로 정책</em>이다.</li> <li>에이전트가 행동을 하려면 <em>특정 상태가 아닌 모든 상태에 대해 어떤 행동을 해야 할지 알아야 하는데 이렇게 모든 상태에 대해 에이전트가 어떤 행동을 해야 하는지 정해놓은 것이 정책</em>이다.</li> <li><em>순차적 행동 결정문제를 풀었다고 한다면 제일 좋은 정책을 에이전트가 얻었다는 것</em>으로 여기서 제일 좋은 정책은 <strong>최적 정책(Optimal Policy)</strong> 이라고 하며 <em>에이전트는 최적 정책에 따라 행동했을 때 보상의 합을 최대</em>로 받을 수 있습니다.</li> </ul> </li> </ol> <blockquote> <p>강화 학습은 문제의 정의를 어떻게 설정하느냐에 따라 학습을 잘하는 지가 결정되고 적절한 보상을 받으며 에이전트가 학습할 수 있게 하는 것이 중요하다. 따라서 에이전트가 판단하기에 충분한 정보를 얻을 수 있도록 순차적 행동 결정 문제를 정의해야 한다.</p> </blockquote> <h2 id="아타리-브레이크-아웃-atari-breakout">아타리 브레이크 아웃 Atari Breakout</h2> <ul> <li>딥마인드는 <em>“Playing Atari with Deep Reinforcement Learning”</em> 논문을 통해 브레이크아웃(Breakout) 게임에서 MDP를 어떻게 구성할지 그리고 에이전트는 어떻게 학습할지를 발표했다.</li> </ul> <ol> <li>MDP <img src="https://user-images.githubusercontent.com/28593767/116837612-21190080-ac06-11eb-9375-cc79e00ef5d7.png" alt="mdp"/></li> </ol> <ul> <li>상태 <ul> <li>브레이크아웃에서 에이전트가 환경으로부터 받아들이는 상태는 게임 화면이다.</li> <li>에이전트가 상황을 파악할 수 있도록 같은 화면을 연속으로 4개를 받아 이 4개의 화면이 하나의 상태로 에이전트에게 제공된다.</li> <li>만일 현재의 이미지 하나만 입력으로 받는다면 게임 화면이 어떤 상황인지 알 수 없으므로 공이 어느 방향으로 움직이는지에 대한 정보가 필요하므로 4개의 연속된 이미지를 입력으로 받는다.</li> </ul> </li> <li>행동 <ul> <li>브레이크아웃에서는 제자리, 왼쪽, 오른쪽, 발사가 가능하고 발사는 게임을 시작할 때 사용한다.</li> <li>즉 에이전트가 게임 도중에 취할 수 있는 행동은 발사를 제외한 3가지로 볼 수 있다.</li> </ul> </li> <li>보상 <ul> <li>벽돌이 깨질 때마다 보상을 +1점씩 받고 더 위쪽을 깰수록 더 큰 보상을 받는다.</li> <li>아무것도 깨지 않을 때는 보상으로 0을 받는다.</li> <li>공을 놓쳐서 목숨을 잃을 경우에 보상으로 -1을 받는다.</li> </ul> </li> </ul> <ol> <li>학습 <img src="https://user-images.githubusercontent.com/28593767/116837613-22e2c400-ac06-11eb-84b0-327ba9dad2ab.png" alt="train"/></li> </ol> <ul> <li>처음에 에이전트는 게임이나 상황에 대해 전혀 모르고 무작위로 제자리, 왼쪽, 오른쪽으로 움직인다.</li> <li>그러다가 에이전트가 우연히 벽돌을 깨면 게임의 환경으로부터 +1의 보상을 받고 공을 놓친다면 -1의 보상을 받는다.</li> <li>이러한 상황을 반복하여 에이전트는 게임을 하면서 어떻게 해야 공을 떨어뜨리지 않고 벽을 깰 수 있는지 학습할 수 있다.</li> <li>강화 학습을 통해 학습되는 것은 인공신경망으로 <em>입력으로 앞서 살펴본 4개의 연속적인 게임 화면이 들어오면 인공신경망으로 그 상태에서 에이전트가 할 수 있는 각 행동이 얼마나 좋은지 출력</em>으로 내놓는다. <ul> <li>행동이 얼마나 좋은지가 행동의 가치가 되고 이것을 <strong>Q Function</strong> 이라고 한다.</li> <li>이 때 사용된 인공신경망을 <strong>DQN(Deep Q-Network)</strong> 라고 한다.</li> <li>에이전트는 DQN이 출력한 큐함수를 보고 큰 가치를 지니는 행동을 선택하고 환경은 에이전트에게 보상과 다음 상태를 알려준다.</li> <li>에이전트는 이렇게 환경과 상호작용하면서 DQN을 더 많은 보상을 받도록 조금씩 조정한다.</li> </ul> </li> </ul> <h3 id="병렬성-parallelism">병렬성 Parallelism</h3> <ul> <li>강화 학습은 경험을 쌓는 부분(시뮬레이터)의 병렬성을 쉽게 증가시킬 수 있다.</li> <li>혼자서 혼자서 시행착오를 통해서 배운다면 한참 걸리겠지만 무수히 늘어난 병렬성의 힘 아래에서는 어려운 지식도 빠르게 습득할 수 있다.</li> <li>OpenAI가 Dota2에 강화 학습을 적용할 때에는 시뮬레이션을 위해 256개의 GPU와 12만 8천 개의 CPU 코어가 사용되었다고 한다.</li> <li>알파고 역시 같은 방식으로 학습되어 이겼던 경기에서 뒀던 수들을 좀 더 자주 두도록 하고 졌던 경기에서 뒀던 수들은 덜 두도록 조정되었다.</li> </ul> <h3 id="자가-학습-self-learning">자가 학습 Self-Learning</h3> <ul> <li>강화 학습은 그냥 시뮬레이션 환경 속에 던져 놓고 달성해야할 목적 만을 알려주며 알아서 배우게 한다.</li> <li>그러면 에이전트는 수 없이 많은 시행착오를 겪어가며 목적을 달성할 방법을 깨닫는다.</li> <li>알파고 또한 학습 초기에는 프로 바둑기사들의 기보를 통해 지도 학습을 진행했지만 이후 자가 학습에 기반을 둔 강화 학습을 통해 사람을 뛰어넘을 수 있었다.</li> </ul> <h2 id="mdp의-구성-요소">MDP의 구성 요소</h2> <p><img width="1175" alt="mdp2" src="https://user-images.githubusercontent.com/28593767/116837614-237b5a80-ac06-11eb-9b14-707d34bf5d8a.png"/></p> <ul> <li>MDP를 통해 정의된 문제에서 에이전트가 학습하기 위해 가치 함수라는 개념을 도입하는데, 이 개념은 <strong>벨만 방정식(Bellman Equation)</strong> 과 연결된다.</li> <li>MDP는 상태와 행동을 포함한 보상 함수, 상태 변환 확률, 감가율(할인율)로 구성되어 있다. <ol> <li><strong>상태</strong></li> </ol> <ul> <li><img width="498" alt="state" src="https://user-images.githubusercontent.com/28593767/116837621-25ddb480-ac06-11eb-88f2-b35253e31a5b.png"/></li> <li><strong>S는 에이전트가 관찰 가능한 상태의 집합</strong>으로 상태란 <em>자신의 상황에 대한 관찰</em>이라고 할 수 있다.</li> <li>MDP에서 상태는 시간에 따라 확률적으로 변하고 <em>시간 t에서의 상태 𝑆_t가 어떤 상태 s다</em>라고 표현한다. <ol> <li><strong>행동</strong></li> </ol> </li> <li><strong>에이전트가 상태 S_t에서 할 수 있는 가능한 행동의 집합은 A</strong>라고 표현한다.</li> <li>보통 에이전트가 할 수 있는 행동은 모든 상태에서 같으므로 하나의 집합 A로 나타내고 어떤 특정한 행동은 a라고 표현한다.</li> <li>에이전트가 특정 행동을 했을 때 어디로 이동할지 결정하는 것이 상태 변환 확률이다. <ol> <li><strong>보상 함수</strong></li> </ol> </li> <li><img width="358" alt="reward" src="https://user-images.githubusercontent.com/28593767/116837619-25451e00-ac06-11eb-975d-72a7d7bdc089.png"/></li> <li>보상은 <strong>에이전트가 학습할 수 있는 유일한 정보로서 환경이 에이전트에게 주는 정보</strong>이다.</li> <li>위 보상 함수는 시간 t일때 상태가 S_t = s이고 그 상태에서 행동 A_t = a를 했을 경우에 받을 보상에 대한 기댓값 E를 나타난 함수이다. <ul> <li>기댓값은 <em>어떤 정확한 값이 아니라 나오게 될 숫자에 대한 예상</em>이다.</li> <li>환경에 따라서 <em>같은 상태에서 같은 행동을 취하더라도 다른 보상을 줄 수도</em> 있기 때문에 보상 함수를 기댓값으로 표현한다.</li> </ul> </li> <li>보상 함수에서 중요한 점은 에이전트가 어떤 상태에서 행동한 것은 시간 t이지만 보상을 받는 것은 t+1인데 이는 보상을 에이전트가 알고 있는 것이 아니고 환경이 알려주는 것이기 때문이다.</li> <li>에이전트가 상태 s에서 행동 a를 하면 환경은 에이전트가 가게 되는 다음 상태 s’과 에이전트가 받을 보상을 에이전트에게 알려준다. <ol> <li><strong>상태 변환 확률</strong></li> </ol> </li> <li><img width="343" alt="prob" src="https://user-images.githubusercontent.com/28593767/116837620-25451e00-ac06-11eb-8378-60edfe78f540.png"/></li> <li>상태의 변화에는 확률적인 요인이 들어가는데 이를 수식으로 표현한 것이 상태 변환 확률이다.</li> <li><strong>상태 변환 확률은 상태 s에서 행동 a를 취했을 때 다른 상태 s’에 도달할 확률</strong>로 보상과 마찬가지로 에이전트가 알지 못하는 값으로서 에이전트가 아닌 환경의 일부이다.</li> <li>상태 변환 확률은 환경의 <strong>모델(Model)</strong> 이라고도 하는데, 환경은 에이전트가 행동을 취하면 상태 변환 확률을 통해 다음에 에이전트가 갈 상태를 알려준다. <ol> <li><strong>감가율(할인율)</strong></li> </ol> </li> <li><img width="421" alt="discount" src="https://user-images.githubusercontent.com/28593767/116837615-2413f100-ac06-11eb-9708-eaaa328b33ca.png"/></li> <li>에이전트가 항상 현재에 판단을 내리기 때문에 현재에 가까운 보상일수록 더 큰 가치를 가진다.</li> <li><strong>에이전트는 그 보상이 얼마나 시간이 지나서 받는지를 고려해서 현재의 가치로 따지므로 감가율이란 미래를 평가 절하하는 항</strong>이라고 할 수 있다.</li> <li><em>현재와 미래 사이에는 다양한 확률적 요소들이 있고 이로 인해 당장 느끼는 가치에 비해 미래에 느끼는 가치가 달라질 수 있으므로 미래의 가치에는 불확실성을 반영하고자 감쇠</em>를 해준다. <ol> <li><strong>정책</strong></li> </ol> </li> <li><img width="304" alt="policy" src="https://user-images.githubusercontent.com/28593767/116837731-94227700-ac06-11eb-874a-7b70f6f0a0d8.png"/></li> <li>정책은 모든 상태에서 에이전트가 할 행동으로 <strong>상태가 입력으로 돌아오면 해야할 행동을 출력으로 내보내는 일종의 함수</strong>라고 할 수 있다.</li> <li>정책은 각 상태에서 단 하나의 행동 만을 나타낼 수도 있고 확률적으로 a1 = 10%, a2 = 90%와 같이 나타낼 수도 있다.</li> <li>에이전트의 최적 정책은 각 상태에서 단 하나의 행동만을 선택하지만 <em>에이전트가 학습하고 있을 때는 정책이 하나의 행동만을 선택하기 보다는 확률적으로 여러 개의 행동을 선택할 수 있어야 한다</em>.</li> <li>정책의 수식은 시간 t에 𝑆_t = s에 에이전트가 있을 때 가능한 행동 중에서 A_t = a를 할 확률을 나타낸다.</li> <li>즉, <em>최적 정책을 얻기 위해서 현재의 정책보다 더 좋은 정책을 학습해나가야 하는것이 강화학습</em>이다.</li> </ul> </li> </ul> <p><img width="574" alt="rl" src="https://user-images.githubusercontent.com/28593767/116837728-9258b380-ac06-11eb-823a-f7f911d599dc.png"/></p> <blockquote> <p>에이전트는 현재 상태에서 앞으로 받을 보상들을 고려해서 행동을 결정하고 환경은 에이전트에게 실제 보상과 다음 상태를 알려준다. 이러한 과정을 반복하면서 초기 에이전트는 어떤 상태에서 앞으로 받을 것이라 예상했던 보상에 대해 틀렸다는 것을 알게 된다. 이 때 앞으로 받을 것이라 예상하는 보상을 가치 함수라고 하며 에이전트는 실제로 받은 보상을 토대로 가치 함수와 정책을 바꿔 나간다. 이러한 학습과정을 충분히 반복한다면 가장 많은 보상을 받게 하는 최적 정책을 학습할 수 있다.</p> </blockquote>]]></content><author><name></name></author><category term="bootcamp"/><category term="study"/><category term="note"/><summary type="html"><![CDATA[강화 학습 Reinforcement Learning]]></summary></entry><entry><title type="html">database</title><link href="https://wonkwonlee.github.io/blog/2021/database/" rel="alternate" type="text/html" title="database"/><published>2021-04-28T00:00:00+00:00</published><updated>2021-04-28T00:00:00+00:00</updated><id>https://wonkwonlee.github.io/blog/2021/database</id><content type="html" xml:base="https://wonkwonlee.github.io/blog/2021/database/"><![CDATA[<h1 id="데이터베이스-database">데이터베이스 Database</h1> <h2 id="데이터베이스의-정의">데이터베이스의 정의</h2> <p><img width="723" alt="db" src="https://user-images.githubusercontent.com/28593767/116032087-fd036f80-a699-11eb-91cf-14dcab1a563f.png"/></p> <ul> <li>데이터베이스는 간단하게 말해 <strong>데이터의 집합</strong> 이라고 할 수 있고 <strong>DBMS(DataBase Management System)</strong> 는 이 데이터베이스를 관리, 운영하는 역할을 하는 소프트웨어라고 할 수 있다.</li> <li>데이터베이스는 여러 명의 사용자나 응용 프로그램이 공유하고 동시에 접근이 가능해야 한다. <ul> <li>Excel과 같은 프로그램은 데이터의 집합으로 사용될 수 있지만, 대용량을 관리하거나 여러 명의 사용자가 공유하는 개념은 아니므로 DBMS가 아니다.</li> </ul> </li> <li>또한 데이터베이스는 <em>데이터의 저장공간 자체를 의미</em>하기도 한다. <ul> <li>MySQL에서는 데이터베이스를 자료가 저장되는 디스크 공간(주로 파일로 구성)으로 취급한다.</li> </ul> </li> <li>종종 데이터베이스와 DBMS를 혼용해서 사용하기도 하지만 정확하게는 <em>데이터베이스는 데이터의 집합 또는 데이터의 저장 공간</em>이라고 할 수 있고 <em>DBMS는 데이터베이스를 운영하는 소프트웨어</em>를 의미한다.</li> </ul> <h2 id="데이터베이스의-특징">데이터베이스의 특징</h2> <ul> <li><strong>데이터의 무결성 Data Integrity</strong> <ul> <li>데이터베이스 안의 데이터는 어떤 경로를 통해 들어 왔던지 <em>데이터에 오류가 있어서는 안된다</em>.</li> <li>이러한 무결성을 위해서 데이터베이스는 <em>제약 조건</em>이라는 특성을 지닌다.</li> <li>예를 들어, 학생 데이터에서 모든 학생은 학번이 반드시 있고 각 학생의 학번은 서로 중복되면 안 되는 제약 조건이 있다면 학번 만을 가지고 정확한 학생을 추출할 수 있다.</li> </ul> </li> <li><strong>데이터의 독립성 Data Independence</strong> <ul> <li>데이터베이스의 크기를 변경하거나 데이터 파일의 저장소를 변경하더라도 <em>기존에 작성된 응용프로그램은 전혀 영향을 받지 않아야 한다</em>.</li> <li>즉, 서로 의존적 관계가 아닌 <em>독립적인 관계</em>여야 한다.</li> <li>예를 들어, 데이터베이스가 저장된 디스크가 새 것으로 변동되어도 기존에 사용하던 응용 프로그램은 아무런 변경 없이 계속 사용되어야 한다.</li> </ul> </li> <li><strong>보안 Security</strong> <ul> <li>데이터베이스 안의 데이터에 아무나 접근할 수 있는 것이 아니라 <em>데이터를 소유한 사람이나 데이터에 접근이 허가된 사람만 접근</em>할 수 있어야 한다.</li> <li>접근할 때도 <em>사용자의 계정에 따라서 다른 권한</em>을 가져야한다.</li> <li>최근 고객 정보 유출 사고가 빈번한 만큼 보안은 더욱 중요한 데이터베이스의 이슈라고 할 수 있다.</li> </ul> </li> <li><strong>데이터 중복의 최소화 Data Duplication Avoidance</strong> <ul> <li>동일한 데이터가 <em>여러 개 중복되어 저장되는 것을 방지</em>한다.</li> <li><em>하나의 테이블에 저장하고 공유</em>함으로써 데이터 중복을 최소화 시킨다.</li> <li>예를 들어, 학생 정보를 교직원 별로 별도의 엑셀 파일에 저장하는 대신 데이터베이스에 통합하여 하나의 테이블에 저장해서 관리한다.</li> </ul> </li> <li><strong>응용 프로그램 제작 및 수정 용이 Easy Implementation and Modification</strong> <ul> <li>기존 파일시스템을 사용할 때는 각각 파일의 포맷에 맞춰 개발해야 하는 응용 프로그램을 데이터 베이스를 이용함으로써 <em>통일된 방식으로 응용 프로그램 작성이 가능해지고 유지 보수 또한 쉬워진다.</em></li> </ul> </li> <li><strong>데이터의 안전성 향상 Data Durability</strong> <ul> <li>대부분의 DBMS가 제공하는 백업, 복원 기능을 이용함으로써, <em>데이터가 깨지는 문제가 발생할 경우에 원상으로 복원 또는 복구하는 방법이 명확</em>해진다.</li> </ul> </li> </ul> <h2 id="데이터베이스의-발전">데이터베이스의 발전</h2> <p>초창기의 컴퓨터에는 데이터베이스라는 개념이 없었지만 다음의 몇 가지 단계를 거치며 데이터베이스가 개발되고 사용되기 시작했다.</p> <ol> <li>오프라인으로 관리 <ul> <li>컴퓨터가 없던 시기에도 회사를 운영하기 위해서는 수입과 지출이 있었을 것이고 그것을 수기로 기록하며 데이터를 관리했었다.</li> </ul> </li> <li>파일 시스템의 사용 <ul> <li>컴퓨터를 사용하면서 종이에 기록하던 내용을 컴퓨터 파일에 기록 저장하게 되었다.</li> <li>응용 프로그램들은 파일에 저장된 내용을 읽고 쓰는 기능이 있고 컴퓨터에 저장된 파일의 내용은 읽고, 쓰기가 편한 약속된 형태의 구조를 지닌다.</li> <li>파일 시스템은 대개 하나의 응용 프로그램마다 하나의 데이터 파일이 할당되기 때문에 어떠한 기능을 구현하기 위해서 기능의 개수만큼 데이터 파일의 숫자가 필요하다.</li> <li>따라서, 데이터의 양이 증가하면 데이터의 중복으로 인한 불일치가 발생하게 된다.</li> </ul> </li> <li>데이터베이스 관리 시스템 (DBMS) <ul> <li>파일 시스템의 단점을 보완하고 <em>대량의 데이터를 보다 효율적으로 관리하고 운영하기 위해서 사용</em>되기 시작한 것이 DBMS이다.</li> <li>DBMS는 데이터의 집합인 데이터베이스를 잘 관리하고 운영하기 위한 시스템 또는 소프트웨어로 DBMS에 <em>데이터를 구축하고 관리하고 활용하기 위해서 사용되는 언어가 SQL</em>이다.</li> </ul> </li> </ol> <h2 id="dbms-분류">DBMS 분류</h2> <ul> <li>DBMS의 유형은 크게 계층형, 망형, 관계형, 객체 지향형, 그리고 객체 관계형 등으로 분류된다</li> <li>현재 사용되는 DBMS 중에는 관계형 DBMS가 가장 많은 부분을 차지한다.</li> <li>MySQL과 Oracle 등은 대표적인 관계형 DBMS이다.</li> </ul> <h3 id="관계형-dbms-relational-dbms">관계형 DBMS Relational DBMS</h3> <ul> <li>관계형 DBMS는 테이블이라 불리는 최소 단위로 구성되어 있고 각 테이블은 하나 이상의 열로 구성되어 있다.</li> <li>RDBMS는 정보를 저장하기 위해서 하나의 테이블이 아닌 <em>여러 개의 테이블로 나누어서 저장</em>함으로써 불필요한 공간의 낭비를 줄이고 데이터 저장의 효율성을 보장할 수 있다.</li> <li>테이블의 관계를 <strong>기본 키(Primary Key)</strong> 와 <strong>외래 키(Foreign Key)</strong> 를 사용해서 맺어 줌으로써 <em>두 테이블을 부모와 자식의 관계</em>로 묶어줄 수 있다. <ul> <li>부모 테이블과 자식 테이블을 조합해서 결과를 얻고자 할 때는 SQL의 <strong>조인(JOIN)</strong> 기능을 이용한다.</li> </ul> </li> <li>관계형 DBMS의 장점은 다른 DBMS에 비해서 업무가 변화될 경우에 쉽게 변화에 순응할 수 있는 구조이며 <em>유지보수 측면에서도 편리</em>하다는 점이다.</li> <li>또한, 대용량 데이터의 관리와 데이터 무결성의 보장을 잘 해주기 때문에 <em>동시에 데이터에 접근하는 응용 프로그램을 사용할 경우에 RDBMS는 적절한 선택</em>이 될 수 있다.</li> <li>RDBMS의 가장 큰 단점은 <em>시스템 자원을 많이 차지해서 시스템이 전반적으로 느려진다</em>는 점이다.</li> </ul> <h2 id="정보시스템-구축-절차-요약">정보시스템 구축 절차 요약</h2> <p>정보시스템을 구축하기 위해서는 일반적으로 <em>분석, 설계, 구현, 시현, 유지보수</em>의 5가지 단계를 거친다.</p> <ul> <li><strong>분석 단계</strong> <ul> <li>구현하고자 하는 프로젝트의 가장 첫 번째 단계로 <em>시스템 분석 또는 요구사항 분석</em>이라고 하며 <em>현재 우리가 <strong>무엇을</strong> 할 것인지를 결정</em>한다.</li> <li>사용자의 인터뷰와 업무 조사 등을 수행해야 하고 분석의 결과로서 많은 문서를 작성해야 한다.</li> </ul> </li> <li><strong>설계 단계</strong> <ul> <li>시스템 설계 또는 프로그램 설계라고 하며 <em>우리가 구축하고자 하는 시스템을 <strong>어떻게</strong> 할 것인지를 결정</em>한다.</li> <li>시스템 설계가 끝나면 설계서에 나온 그대로 프로그램을 작성하므로 일반적으로 시스템 설계가 끝나면 가장 큰 작업이 끝난 것으로 간주한다.</li> <li>대부분의 프로젝트에서 이 분석과 설계의 과정이 전체 공정의 50% 이상을 차지한다.</li> </ul> </li> </ul> <h2 id="데이터베이스-모델링과-필수-용어">데이터베이스 모델링과 필수 용어</h2> <ul> <li>분석과 설계 과정 중에서 가장 중요한 과정 중의 하나가 <strong>데이터베이스 모델링</strong>이다.</li> <li>데이터베이스 모델링이란 <em>현실 세계에서 사용되는 데이터를 MySQL에 어떻게 옮겨 놓을 것인지를 결정하는 과정</em>이라고 할 수 있다.</li> </ul> <p><img width="1343" alt="db_diagram" src="https://user-images.githubusercontent.com/28593767/116175118-ad30b100-a74a-11eb-8695-ceee06adf20c.png"/></p> <h3 id="데이터베이스-용어">데이터베이스 용어</h3> <ul> <li><strong>데이터</strong> : 이멋사, 컴퓨터, 2023.2.1 과 같이 하나하나의 단편적인 정보를 뜻한다. <ul> <li>즉, 정보는 있으나 아직 <em>체계화 되지 못한 상태</em>를 의미한다.</li> </ul> </li> <li><strong>테이블</strong> : 회원이나 제품의 데이터를 입력하기 위해, <em>표 형태로 표현한 것</em>을 의미한다. <ul> <li>지금은 인터넷 쇼핑몰을 구현하기 위해서, 회원에 대한 정보를 보관할 회원 테이블과 제품 정보를 보관할 제품 테이블 등 두 개의 테이블을 만들었다.</li> </ul> </li> <li><strong>데이터베이스</strong> : 테이블이 저장되는 저장소를 의미하고 보통 원통 모양으로 표현한다. <ul> <li>각 데이터베이스는 <em>서로 다른 고유한 이름</em>을 가지고 있어야 한다.</li> <li>우리가 사용하게 될(또는 만들게 될) 데이터베이스는 쇼핑몰 데이터베이스이다.</li> </ul> </li> <li><strong>DBMS</strong> : DataBase Management System의 약자로 데이터베이스를 관리하는 시스템 또는 소프트웨어를 말한다.</li> <li><strong>열(=컬럼 =필드)</strong> : 각 테이블은 열로 구성됩다. <ul> <li>회원 테이블의 경우에는 아이디, 회원 이름, 주소 등 3개의 열로 구성되어 있다.</li> </ul> </li> <li><strong>열 이름</strong> : 각 열을 구분하기 위한 이름으로 <em>각 테이블 내에서는 중복되지 않고 고유</em>해야 한다. <ul> <li>회원 테이블의 아이디, 회원 이름, 주소 등이 열 이름이다.</li> </ul> </li> <li><strong>데이터 형식</strong> : <em>열의 데이터 형식</em>을 의미하고 테이블을 생성할 때 열 이름과 함께 지정해줘야 한다. <ul> <li>회원 테이블의 회원 이름 열은 당연히 숫자 형식이 아닌, 문자 형식이어야 한다.</li> <li>또한, 제품 테이블의 가격 열은 숫자(특히 정수) 형식이어야 한다.</li> </ul> </li> <li><strong>행(=로우 =레코드)</strong> : <em>실질적인 데이터</em>를 의미한다. <ul> <li>예를 들어 <em>bbb0202/김멋사/서울 은평구 증산동</em>이 하나의 행으로 행 데이터라고도 부른다.</li> <li>회원 테이블의 예로 회원이 몇 명인지는 행 데이터가 몇 개 있는지와 동일한 의미이다.</li> </ul> </li> <li><strong>기본 키(Primary Key) 열</strong> : <em>기본 키 열은 각 행을 구분하는 유일한 열</em>을 의미하며 <em>중복 되어서는 안되고 비어 있어서도 안되며, 각 테이블에는 기본 키가 하나만 지정</em>되어 있어야 한다. <ul> <li>예시에서는 회원 테이블의 기본 키가 아이디 열에 지정되어 있다.</li> <li>아이디는 아이디 중복 확인 검사를 통해 중복되지 않게 지정되기 때문에 기본키로 설정하기에 적합하다.</li> </ul> </li> <li><strong>외래 키(Foreign Key) 필드</strong> : <em>두 테이블의 관계를 맺어주는 키</em>를 의미한다.</li> </ul> <p><img width="1020" alt="db_proc" src="https://user-images.githubusercontent.com/28593767/116175488-5bd4f180-a74b-11eb-8580-8dbb062e4247.png"/></p> <h2 id="데이터베이스-개체-활용">데이터베이스 개체 활용</h2> <h3 id="인덱스-index">인덱스 Index</h3> <p><img width="653" alt="idx" src="https://user-images.githubusercontent.com/28593767/116338584-ef272900-a816-11eb-9233-a44079618e2f.png"/></p> <p><img width="780" alt="idx2" src="https://user-images.githubusercontent.com/28593767/116338574-eb93a200-a816-11eb-96bb-67b55802b2fe.png"/></p> <p><img width="793" alt="idx3" src="https://user-images.githubusercontent.com/28593767/116338578-edf5fc00-a816-11eb-8606-23dae11cb7f3.png"/></p> <ul> <li>인덱스란 대부분의 책의 제일 뒤에 붙어있는 찾아보기와 같은 개념으로 수 많은 데이터에서 인덱스 없이 전체 데이터를 찾을 경우 시간이 매우 오래걸리게 된다.</li> <li><em>데이터베이스 튜닝이란 데이터베이스의 성능을 향상시키거나 응답하는 시간을 단축시키는 것</em>을 의미한다. <ul> <li>쿼리에 대한 응답을 줄이기 위해서 가장 집중적으로 보는 부분 중 하나가 인덱스로, 인덱스를 적절히 활용하고 있느냐에 따라서 시스템의 성능이 몇 배에서 몇 십 배 이상 차이가 날 수 있다.</li> </ul> </li> <li>인덱스는 테이블의 열 단위에 생성된다.</li> </ul> <h3 id="뷰-view">뷰 View</h3> <p><img width="566" alt="view0" src="https://user-images.githubusercontent.com/28593767/116338581-ef272900-a816-11eb-9bd6-d1556899408a.png"/></p> <p><img src="https://user-images.githubusercontent.com/28593767/116235627-0f180780-a799-11eb-8009-440302102605.png" alt="view"/></p> <ul> <li>뷰란 <em>가상의 테이블</em>로 사용자 입장에서는 테이블과 동일하게 보이지만 뷰는 실제 행 데이터를 가지고 있지 않고 <em>진짜 테이블에 링크된 개념</em>이다.</li> <li>따라서 뷰를 SELECT하면 실제 테이블의 데이터를 조회하는 것과 동일한 결과가 된다.</li> <li>뷰를 이용하면 권한이 낮은 사용자가 개인 정보 유출의 위험없이 데이터를 조회할 수 있다.</li> </ul> <h3 id="스토어드-프로시저-stored-procedure">스토어드 프로시저 Stored Procedure</h3> <p><img width="606" alt="procedure" src="https://user-images.githubusercontent.com/28593767/116338585-efbfbf80-a816-11eb-8c56-61ea4ec23d58.png"/></p> <ul> <li>스토어드 프로시저란 <em>MySQL에서 제공해주는 프로그래밍 기능</em>으로 간단히 말해 <em>SQL문을 하나로 묶어서 편리하게 사용하는 기능</em>이라고 할 수 있다. <ul> <li>SQL을 묶는 개념 외에 다른 프로그래밍 언어와 같은 기능을 담당할 수도 있다.</li> </ul> </li> <li>실무에서는 SQL문(주로 SELECT)을 매번 하나하나 수행하기 보다는 스토어드 프로시저를 만들어 놓은 후에 호출하는 방식을 많이 사용한다.</li> </ul> <h3 id="트리거-trigger">트리거 Trigger</h3> <p><img width="619" alt="trigger" src="https://user-images.githubusercontent.com/28593767/116338586-f0585600-a816-11eb-85bf-44cbaf66e018.png"/></p> <ul> <li>트리거란 <em>테이블에 부착되어서 테이블에 INSERT나 UPDATE 또는 DELETE 작업이 발생되면 실행되는 코드</em>를 말한다.</li> <li>회원이 탈퇴할 경우 회원 테이블(memberTBL) 에서 정보를 삭제하면서 자동으로 삭제될 데이터를 삭제회원 테이블(deletedMemberTBL) 에 저장할 수 있다.</li> </ul> <h2 id="프로젝트의-진행">프로젝트의 진행</h2> <ul> <li>프로젝트란 <em>현실 세계의 업무를 컴퓨터 시스템으로 옮겨놓는 일련의 과정</em>이라고 할 수 있다.</li> <li>즉, 프로젝트란 <em>대규모의 프로그램을 작성하기 위한 전체 과정</em>이다.</li> </ul> <h3 id="폭포수-모델-waterfall-model">폭포수 모델 Waterfall Model</h3> <p><img width="768" alt="waterfall" src="https://user-images.githubusercontent.com/28593767/116349433-f3f5d800-a82a-11eb-9b89-edbd2a9c5dbd.png"/></p> <ul> <li><em>소프트웨어 공학은 다른 공학 분야의 것을 소프트웨어 분야에 가져와서 적합하도록 수정한 것으로 소프트웨어 개발 방법론의 일환</em>이다.</li> <li><strong>폭포수 모델</strong>은 가장 오래되고 전통적으로 사용되는 소프트웨어 개발 모델로 폭포가 떨어지듯이 각 단계가 끝나면 다음 단계로 진행한다.</li> <li>폭포수 모델의 장점은 <em>각 단계가 명확히 구분되어서 프로젝트의 진행 단계가 명확</em>해진다는 점이다.</li> <li>폭포수 모델의 단점은 <em>문제점이 발생될 경우에는 다시 앞단계로 거슬러 올라가기가 어렵다</em>는 점이다. <ul> <li>또한 문제점이 초기 단계인 업무 분석이나 시스템 설계에서 나오기보다는 대부분 프로그램 구현 단계나 테스트 단계에서 나오다보니 <em>대부분 업무 분석 단계로 거슬러 올라가서 다시 시작</em>해야 한다.</li> </ul> </li> <li>가장 핵심적인 단계는 업무 분석과 시스템 설계로 대부분의 소프트웨어 프로젝트는 이 두 단계를 합쳐서 전체 공정의 최소 50% 이상을 할당한다.</li> <li>실패하는 대부분의 프로젝트는 주로 프로그램 구현에 비중을 많이 두는 경우로, 복잡한 시스템을 구현하기 위해서 <em>구현(코딩)은 분석과 설계에 비해서 낮은 중요도</em>를 갖는다.</li> <li><em>데이터베이스 모델링은 분석과 설계 단계에서 가장 중요한 작업 중 하나</em>라고 할 수 있다.</li> </ul> <h3 id="데이터베이스-모델링-database-modelling">데이터베이스 모델링 Database Modelling</h3> <ul> <li>데이터베이스 모델링은 <strong>*개념적 모델링, 논리적 모델링, 물리적 모델링</strong>의 3단계를 거쳐서 완성된다.</li> <li>개념적 모델링은 주로 업무 분석 단계에 포함되며 논리적 모델링은 업무 분석의 후반부와 시스템 설계의 전반부에 걸쳐서 진행되고 물리적 모델링은 시스템 설계의 후반부에 주로 진행된다.</li> </ul>]]></content><author><name></name></author><category term="bootcamp"/><category term="study"/><category term="note"/><summary type="html"><![CDATA[데이터베이스 Database]]></summary></entry><entry><title type="html">natural language processing</title><link href="https://wonkwonlee.github.io/blog/2021/natural-language-processing/" rel="alternate" type="text/html" title="natural language processing"/><published>2021-04-23T00:00:00+00:00</published><updated>2021-04-23T00:00:00+00:00</updated><id>https://wonkwonlee.github.io/blog/2021/natural-language-processing</id><content type="html" xml:base="https://wonkwonlee.github.io/blog/2021/natural-language-processing/"><![CDATA[<h1 id="자연어-처리-natural-language-processing">자연어 처리 Natural Language Processing</h1> <h2 id="자연어-처리-nlp">자연어 처리 NLP</h2> <p><img src="https://user-images.githubusercontent.com/28593767/115187514-6b868180-a11e-11eb-8533-d0914bcb1914.png" alt="nlp"/></p> <ul> <li>인간이 일상에서 사용하는 언어를 자연어라고 한다.</li> <li>컴퓨터 분야에서는 자연어 의미를 분석해 컴퓨터가 처리할 수 있도록 하는 일을 <strong>자연어 처리(Natural Language Processing)</strong> 혹은 줄여서 <strong>NLP</strong>라고 한다.</li> <li>일반적으로 문장을 일정한 의미가 있는 <strong>토큰(Token)</strong> 이라는 가장 작은 단어들로 나눈 뒤 나눠진 단어들을 이용해 의미를 분석한다.</li> <li>토큰의 단위는 <strong>토크나이징(Tokenizing)</strong> 방법에 따라 달라질 수 있지만 일반적으로 <em>일정한 의미가 있는 가장 작은 정보 단위로 결정</em>된다.</li> <li><em>토크나이징은 문장 형태의 데이터를 처리하기 위해 제일 처음 수행해야 하는 기본적인 작업이며 주로 텍스트 전처리 과정에서 사용</em>된다.</li> </ul> <h3 id="konlpy">KoNLPy</h3> <ul> <li><a href="https://konlpy-ko.readthedocs.io/ko/v0.4.3/"><strong>KoNLPy</strong></a> 는 한국어 토크나이징을 지원하는 파이썬 라이브러리로 한국어 자연어 처리에 많이 사용된다.</li> <li>한국어 문장을 분석하려면 토크나이징 작업을 제일 먼저 수행해야 하는데, 이때 토큰 단위를 어떻게 정의하느냐에 따라 자연어 처리 성능에 영향을 미친다. <ul> <li>일정한 의미가 있는 가장 작은 말의 단위, 즉 의미가 더 이상 쪼개지지 않는 <strong>형태소(Morpheme)</strong> 를 토큰 단위로 사용한다.</li> </ul> </li> <li>영어의 경우 단어의 변화가 크지 않고, 띄어쓰기로 단어를 구분하기 때문에 공백을 기준으로 토크나이징을 수행해도 큰 문제 없지만 <em>한국어는 명사와 조사를 띄어 쓰지 않고, 용언에 따라 여러 가지 어미가 붙기 때문에 띄어쓰기만으로는 토크나이징할 수 없다</em>.</li> <li>따라서 형태소 분석기를 이용하여 문장에서 형태소를 추출하면서 형태소의 뜻과 문맥을 고려해 품사 태깅을 해줘야 한다.</li> </ul> <h3 id="kkma">Kkma</h3> <ul> <li><a href="http://kkma.snu.ac.kr/documents/?doc=postag"><strong>Kkma</strong></a> 는 서울대학교 IDS(Intelligent Data Systems) 연구실에서 자연어 처리를 위해 개발한 한국형 형태소 분석기로 <em>꼬꼬마</em>라고 발음한다.</li> <li>Kkma는 다음 4가지 함수를 제공한다. <img width="1292" alt="kkma" src="https://user-images.githubusercontent.com/28593767/115185952-cf5b7b00-a11b-11eb-8900-6b10475a3618.png"/></li> </ul> <h3 id="komoran">Komoran</h3> <ul> <li><a href="https://www.shineware.co.kr/products/komoran/#demo?utm_source=komoran-kr&amp;utm_medium=Referral&amp;utm_campaign=github-demo"><strong>Komoran(Korean Morphological ANalyzer)</strong></a> 은 Shinware에서 개발한 자바 기반 한국어 형태소 분석기로 <em>코모란</em>이라고 발음한다.</li> <li>Komoran은 다음 3가지 함수를 제공한다. <img src="https://user-images.githubusercontent.com/28593767/115186644-0c743d00-a11d-11eb-9d0e-9e10321a5402.png" alt="komoran"/></li> </ul> <h3 id="okt">Okt</h3> <ul> <li><a href="https://openkoreantext.org/"><strong>Okt(Opensource Korean Text Processor)</strong></a> 는 트위터에서 개발한 Twitter 한국어 처리기에서 파생된 오픈소스 한국어 처리기이다.</li> <li>Okt의 경우 앞서 소개한 형태소 분석기들보다 분석되는 품사 정보는 작지만 분석 속도는 제일 빠르고 또한 normalize() 함수를 지원해 오타가 섞인 문장을 정규화해서 처리하는데 효과적이지만 성능이 뛰어나지는 않다.</li> <li>Okt는 다음 5가지 함수를 제공한다. <img src="https://user-images.githubusercontent.com/28593767/115187507-69bcbe00-a11e-11eb-9740-bb14fa6aa3ec.png" alt="okt"/></li> </ul> <h3 id="한국어-토크나이징">한국어 토크나이징</h3> <ul> <li>영어의 경우 단순히 토큰 정보만 필요하다면 띄어쓰기만 하더라도 훌륭한 결과를 보여준다.</li> <li>하지만 <em>한국어는 명사와 조사를 띄어쓰지 않고, 용언에 따라 여러 가지 어미가 붙기 때문에 띄어쓰기만으로는 토크나이징을 할 수 없다</em>.</li> <li>따라서 KoNLPy의 형태소 분석기를 이용해 형태소 단위의 토큰과 품사 정보까지 추출하고 추출된 정보에서 필요 없는 정보를 제거하는 <strong>전처리(Preprocessing)</strong> 과정이 추가되어야 한다.</li> </ul> <p><img src="https://user-images.githubusercontent.com/28593767/115188134-71c92d80-a11f-11eb-9dbc-e3db0889475e.png" alt="konlpy"/></p> <h2 id="임베딩-embedding">임베딩 Embedding</h2> <ul> <li>컴퓨터는 수치 연산만 가능하기 때문에 자연어를 숫자나 벡터 형태로 변환해야 한다.</li> <li>임베딩은 <strong>단어나 문장을 수치화해 벡터 공간으로 표현하는 과정</strong>을 의미한다.</li> <li>임베딩은 말뭉치의 의미에 따라 벡터화하기 때문에 문법적인 정보가 포함되어 있다.</li> <li>임베딩 기법에는 문장 전체를 벡터로 표현하는 문장 임베딩과 개별 단어를 벡터로 표현하는 단어 임베딩이 있다. <ul> <li>문장 임베딩의 경우 <em>전체 문장의 흐름을 파악해 벡터로 변환하기 때문에 문맥적 의미를 지니는 장점</em>이 있다.</li> <li>하지만 <em>임베딩하기 위해 많은 문장 데이터가 필요하며 학습하는데 비용</em>이 많이 들어간다.</li> <li>반면 단어 임베딩은 문장 임베딩에 비해 학습 방법이 간단해 <em>실무에서 많이 사용</em>된다.</li> <li>하지만 단어 임베딩은 <em>동음이의어에 대한 구분을 하지 않기 때문에 의미가 다르더라도 단어의 형태가 같다면 동일한 벡터값으로 표현되는 단점</em>이 있다.</li> </ul> </li> <li>단어 임베딩은 말뭉치에서 각각의 단어를 벡터로 변환하는 기법으로 의미와 문법적 정보를 지니고 있으며, 단어를 표현하는 방법에 따라 다양한 모델이 존재한다.</li> </ul> <h3 id="원-핫-인코딩-one-hot-encoding">원-핫 인코딩 One-Hot Encoding</h3> <p><img width="484" alt="onehot" src="https://user-images.githubusercontent.com/28593767/115192638-09317f00-a126-11eb-8c21-4569f91c4aa4.png"/></p> <ul> <li>원-핫 인코딩은 단어를 숫자 벡터로 변환하는 가장 기본적인 방법으로 <em>단 하나의 값만 1이고 나머지 요솟값은 0인 인코딩</em>을 의미한다.</li> <li>원-핫 인코딩으로 나온 결과를 <strong>원-핫 벡터(One-Hot Vector)</strong> 라 하며, 전체 요소 중 단 하나의 값만 1이기 때문에 <strong>희소 벡터(Sparse Vector)</strong> 라고 한다.</li> <li>원-핫 인코딩을 하기 위해서는 단어 집합이라 불리는 사전을 먼저 만들어야 한다. <ul> <li>사전이란 말뭉치에서 나오는 서로 다른 모든 단어의 집합을 의미한다.</li> <li>말뭉치에 존재하는 모든 단어의 수가 원-핫 벡터의 차원을 결정한다.</li> <li>사전 내 단어 순서대로 고유한 인덱스 번호를 부여해 단어의 인덱스 번호가 원-핫 인코딩에서 1의 값을 가지는 요소의 위치가 부여된다.</li> </ul> </li> <li>이처럼 단어가 희소 벡터로 표현되는 방식을 <strong>희소 표현(Sparse Representation)</strong> 이라고 한다. <ul> <li>희소 표현은 각각의 차원이 독립적인 정보를 지니고 있어 사람이 이해하기에 직관적인 장점이 있지만 <em>단어 사전의 크기가 커질수록 메모리 낭비와 계산 복잡도가 커지는 단점</em>이 있다.</li> <li>또한 <em>기본 토큰이 되는 단어의 의미와 주변 단어 간의 관계를 단어 임베딩에 표현할 수 없다는 단점</em>도 있다.</li> </ul> </li> </ul> <h3 id="분산-표현-distributed-representation">분산 표현 Distributed Representation</h3> <p><img width="394" alt="distri" src="https://user-images.githubusercontent.com/28593767/115192633-0767bb80-a126-11eb-9314-086c7f80e740.png"/></p> <ul> <li>분산 표현은 한 단어의 정보가 특정 차원에 표현되지 않고 여러 차원에 분산되어 표현되어 붙여진 이름이다. <ul> <li>원하는 차원에 데이터를 최대한 밀집시킬 수 있어 <strong>밀집 표현(Dense Representation)</strong> 이라 부르기도 하며 밀집 표현으로 만들어 진 벡터를 <strong>밀집 벡터(Dense Vector)</strong> 라고 한다.</li> </ul> </li> <li>희소 표현과 달리 <em>각 단어 간의 유사성을 잘 표현하면서도 벡터 공간을 절약할 수 있는 방법</em>으로 하나의 차원에 다양한 정보를 가지고 있다.</li> <li>분산 표현의 첫번째 장점은 <strong>임베딩 벡터의 차원을 데이터 손실을 최소화하면서 압축할 수 있다</strong>는 점이다. <ul> <li>희소 표현 방식은 단어를 표현하는 데 너무 많은 차원이 필요하고 단어 사전이 커질수록 비효율적이고 희소 벡터이기 때문에 대부분의 값이 0이 된다.</li> <li>입력 데이터의 차원이 너무 높아지면 신경망 모델의 학습이 어려워지는 <strong>차원의 저주(Curse of Dimentionality)</strong> 문제가 발생한다.</li> </ul> </li> <li>또한 분산 표현의 두 번째 장점은 <strong>임베딩 벡터에는 단어의 의미, 주변 단어간의 관계 등 많은 정보가 표현되어 있어 일반화 능력이 뛰어나다</strong>는 점이다. <ul> <li>예를 들어 남자와 남성이라는 단어가 있을 때 희소 표현 방식에는 그저 단 하나의 요솟값에 불과하다.</li> <li>즉, 남자와 남성의 관계가 전혀 표현되어 있지 않는다.</li> <li>하지만 분산 표현에서는 <em>벡터 공간 상에서 유사한 의미를 갖는 단어들은 비슷한 위치에 분포</em>되어 있기 때문에 남자와 남성의 단어 위치는 매우 가깝다.</li> </ul> </li> </ul> <h3 id="word2vec-모델">Word2Vec 모델</h3> <ul> <li>Word2Vec 모델은 신경망 기반 단어 임베딩의 대표적인 방법으로 2013년에 구글에서 발표했으며 가장 많이 사용되는 단어 임베딩 모델이다.</li> <li>기존 신경망 기반의 단어 임베딩 모델에 비해 구조상 차이는 크게 없지만 <em>계산량을 획기적으로 줄여 빠른 학습을 가능</em>하게 하였다.</li> <li>Word2Vec 모델은 <strong>CBOW(Continuous Bag of Words)</strong> 와 <strong>skip-gram</strong> 두 가지 모델로 제안되었다.</li> </ul> <p><img width="891" alt="word2vec" src="https://user-images.githubusercontent.com/28593767/115327256-8f52d180-a1c9-11eb-9bb9-1497384c4c0f.png"/></p> <ul> <li>CBOW 모델은 <strong>맥락(Context Word)이라 표현되는 주변 단어들을 이용해 타겟 단어를 예측</strong>하는 신경망 모델이다. <ul> <li>신경망의 입력을 주변 단어들로 구성하고 출력을 타깃 단어로 설정해 학습된 가중치 데이터를 임베딩 벡터로 활용한다.</li> <li>CBOW 모델은 <em>타깃 단어의 손실만 계산하면 되기 때문에 학습 속도가 빠른 장점</em>이 있다.</li> </ul> </li> <li>skip-gram 모델은 CBOW 모델과 반대로 <strong>하나의 타깃 단어를 이용해 주변 단어들을 예측</strong>하는 신경망 모델이다. <ul> <li>skip-gram 모델은 입출력이 CBOW 모델과 반대로 되어 있기 때문에 예측해야 하는 맥락이 많다.</li> <li>따라서 <em>단어 분산 표현력이 우수해 CBOW 모델에 비해 임베딩 품질이 우수</em>하다.</li> </ul> </li> <li>CBOW 모델에서는 타깃 단어를 예측하기 위해 앞뒤 단어를 확인하는데 이 때 <em>앞뒤로 몇 개의 단어까지 확인할지 결정하는 범위</em>를 <strong>윈도우(Window)</strong> 라고 한다.</li> </ul> <p><img width="915" alt="window_size" src="https://user-images.githubusercontent.com/28593767/115327554-1f911680-a1ca-11eb-8c6b-37b7d5dbe4fd.png"/></p> <ul> <li>Word2Vec의 단어 임베딩은 해당 단어를 밀집 벡터로 표현하며 학습을 통해 의미상 비슷한 단어들을 비슷한 벡터 공간에 위치시킨다.</li> <li>벡터 특성상 의미에 따라 방향성을 지니고 임베딩된 벡터들 간 연산이 가능하기 때문에 단어간 관계를 계산할 수 있다. <ul> <li>왕과 여왕의 방향 차이만큼 남자와 여자의 방향 차이가 생긴다.</li> </ul> </li> </ul> <p><img width="398" alt="wordvec" src="https://user-images.githubusercontent.com/28593767/115328362-7a773d80-a1cb-11eb-9c44-0864b2dacba5.png"/></p> <h2 id="text-similarity-algorithm">Text Similarity Algorithm</h2> <ul> <li>인간은 두 개의 문장에 동일한 단어나 의미상 비슷한 단어들이 얼마나 분포되어 있는지 직감적으로 파악한다.</li> <li>컴퓨터는 <em>임베딩으로 각 단어들의 벡터를 구한 다음 벡터 간의 거리를 계산하는 방법으로 단어 간의 의미가 얼마나 유사 한지 계산</em>할 수 있다.</li> <li>Q&amp;A 챗봇 개발을 위해서는 챗봇 엔진에 입력되는 문장과 시스템에서 해당 주제의 답변과 연관되어 있는 질문이 얼마나 유사 한지 계산할 수 있어야 적절한 답변을 출력할 수 있다.</li> <li>두 문장 간의 유사도를 계산하기 위해서는 문장 내에 존재하는 단어들을 수치화해야 하는데 이 때 언어 모델에 따라 통계를 이용하는 방법과 인공 신경망을 이용하는 방법으로 나눌 수 있다. <ul> <li>Word2Vec은 인공 신경망을 이용한 방법이고 이제 통계적인 방법을 이용해 유사도를 계산하는 방법을 살펴본다.</li> </ul> </li> </ul> <h3 id="n-gram">n-gram</h3> <p><img src="https://user-images.githubusercontent.com/28593767/115339998-e021f480-a1e0-11eb-8ca5-a8b3303bdaca.png" alt="n-gram"/></p> <ul> <li>n-gram은 주어진 문장에서 n개의 연속적인 단어 시퀀스(단어 나열)를 의미한다.</li> <li>n-gram은 문장에서 n개의 단어를 토큰으로 사용하여 <em>이웃한 단어의 출현 횟수를 통계적으로 표현해 텍스트의 유사도를 계산하는 방법</em>이다.</li> <li><em>서로 다른 문장을 n-gram으로 비교하면 단어의 출현 빈도에 기반한 유사도를 계산</em>할 수 있고 이를 통해 논문 인용이나 도용 정도를 조사할 수 있다. <ul> <li>구현하기는 쉽지만 학습 말뭉치 품질만 좋다면 괜찮은 성능을 보여준다.</li> </ul> </li> </ul> <p><img src="https://user-images.githubusercontent.com/28593767/115339999-e1532180-a1e0-11eb-97cb-0a0c1e3e09bf.png" alt="similarity"/></p> <ul> <li>n-gram을 이용한 문장 간의 유사도를 계산 <ol> <li>문장을 n-gram으로 토큰을 분리한 후 <strong>단어 문서 행렬(Term-Document Matrix, DTM)</strong> 을 만든다.</li> <li>두 문장을 서로 비교해 동일한 단어의 출현 빈도를 확률로 계산해 유사도를 구한다.</li> </ol> </li> <li><strong>tf(Term Frequency)</strong> 는 두 문장 A와 B에서 동일한 토큰의 출현 빈도를 뜻하며 tokens는 해당 문장에서 전체 토큰 수를 의미한다. <ul> <li>여기서 토큰은 n-gram으로 분리된 단어를 뜻한다.</li> <li>즉, 위의 Similarity 수식은 <em>기준이 되는 문장 A의 전체 토큰 중 A와 B에 동일한 토큰이 얼마나 있는지를 비율로 나타낸 수식</em>이다.</li> </ul> </li> <li>실무에서는 문서 단위로 유사도를 구하는 경우가 많고 해당 문서에서 단어들이 얼마나 나오는지 출현 빈도를 행렬로 표현한다.</li> </ul> <p><img src="https://user-images.githubusercontent.com/28593767/115342311-06e22a00-a1e5-11eb-8459-5eaa0fc94b68.png" alt="n-gram"/></p> <p>문장 A와 B의 유사도는 4/6, 0.66의 유사도를 가지고 다시 말해 <em>문장 A와 B는 66% 유사하다.</em></p> <h3 id="코사인-유사도-cosine-similarity">코사인 유사도 Cosine Similarity</h3> <p><img width="568" alt="cos" src="https://user-images.githubusercontent.com/28593767/115342307-05b0fd00-a1e5-11eb-8a61-70021a8889f0.png"/></p> <ul> <li>단어나 문장을 벡터로 표현할 때 벡터 간 거리나 각도를 이용해 유사성을 파악할 수 있다.</li> <li>코사인 유사도는 <em>두 벡터간 코사인 각도를 이용해 유사도를 측정하는 방법으로 일반적으로 벡터의 크기가 중요하지 않을 때 그 거리를 측정하기 위해 사용</em>한다. <ul> <li>단어의 출현 빈도를 통해 유사도 계산을 한다면 동일한 단어가 많이 포함되어 있을수록 벡터의 크기가 커지지만 <em>코사인 유사도는 벡터의 크기와 상관없이 결과가 안정적</em>이다.</li> <li>코사인 값은 -1 ~ 1 사이의 값을 가지며 두 벡터의 방향이 완전히 동일한 경우에는 1, 반대 방향인 경우에는 -1, 두 벡터가 서로 직각을 이루면 0의 값을 가진다.</li> <li>즉, 두 벡터의 방향이 같아질 수록 유사한 값을 지닌다.</li> </ul> </li> </ul> <p><img src="https://user-images.githubusercontent.com/28593767/115342313-077ac080-a1e5-11eb-9a69-6ee58db51aae.png" alt="cos2"/></p> <p>문장 A와 B의 코사인 각도는 0.83이고 다시 말해 <em>문장 A와 B는 83% 유사하다.</em></p> <blockquote> <p>자연어 처리를 위해서는 제일 먼저 <strong>토크 나이징을 통해 주어진 문장에서 최소한의 의미를 가지는 단어들을 토큰화</strong> 시켜야 한다. 추출한 토큰들은 아직 자연어 형태이므로 컴퓨터가 연산하거나 처리할 수 없기 때문에 <strong>임베딩 처리를 통해 컴퓨터가 계산하기 용이한 벡터 형태로 수치화</strong> 시키는 과정을 거쳐야 한다. 임베딩된 토큰들은 <strong>출현 빈도를 이용하거나 인공 신경망을 통해 문장 간의 유사도를 계산</strong>할 수 있다.</p> <p><em>챗봇 엔진에 어떤 질문이 입력되었을 때 적절한 답변을 하기 위해서는 입력된 질문과 시스템에 저장되어 있는 질문–답변 데이터의 유사도를 계산할 수 있어야 해당 질문에 연관된 답변을 할 수 있다.</em></p> </blockquote> <h2 id="deep-learning-models">Deep Learning Models</h2> <ul> <li>챗봇 엔진에서 <strong>문장 의도 분류</strong>를 위해서는 <strong>CNN(Convolutional Neural Network) 모델</strong>을 사용한다.</li> <li>일반적으로 이미지 분류에서 좋은 성능을 보이지만 <em>임베딩 품질만 괜찮다면 자연어 분류에도 좋은 성능</em>을 보여준다. <ul> <li>컴퓨터 입장에서는 이미지든 임베딩 처리된 자연어든 <em>수치(벡터)로 표현 가능한 대상이면 특징을 뽑아내도록 CNN 모델을 학습</em>할 수 있다.</li> </ul> </li> </ul> <p><img src="https://user-images.githubusercontent.com/28593767/115499945-5d19a080-a2ab-11eb-98d1-468b23b32234.png" alt="cnn_diagram"/></p>]]></content><author><name></name></author><category term="bootcamp"/><category term="study"/><category term="note"/><summary type="html"><![CDATA[자연어 처리 Natural Language Processing]]></summary></entry><entry><title type="html">recurrent neural network</title><link href="https://wonkwonlee.github.io/blog/2021/recurrent-neural-network/" rel="alternate" type="text/html" title="recurrent neural network"/><published>2021-04-22T00:00:00+00:00</published><updated>2021-04-22T00:00:00+00:00</updated><id>https://wonkwonlee.github.io/blog/2021/recurrent-neural-network</id><content type="html" xml:base="https://wonkwonlee.github.io/blog/2021/recurrent-neural-network/"><![CDATA[<h1 id="순환-신경망-recurrent-neural-network">순환 신경망 Recurrent Neural Network</h1> <h2 id="자연어-처리에서의-순환-신경망-rnn-in-nlp">자연어 처리에서의 순환 신경망 RNN in NLP</h2> <ul> <li>챗봇 엔진에서 <strong>개체명 인식(Named Entity Recognition)</strong> 을 위해서는 <strong>양방향 LSTM(Bi-LSTM) 모델</strong>을 사용한다.</li> <li>LSTM은 순환 신경망 모델의 일종으로 시퀀스 또는 시계열 데이터의 패턴을 인식하는 분야에서 많이 사용한다. <ul> <li>연속적인 데이터의 패턴을 이용해 결과를 예측하므로 주로 주가 예측이나 신호 분석 및 번역분야에서 좋은 성능을 보인다.</li> <li>LSTM은 RNN 모델에서 파생되어 만들어졌다.</li> </ul> </li> </ul> <h2 id="순환-신경망-recurrent-neural-network-1">순환 신경망 Recurrent Neural Network</h2> <p><img width="927" alt="rnn" src="https://user-images.githubusercontent.com/28593767/115508853-bcca7880-a2b8-11eb-961f-754ec4cbfd5a.png"/></p> <ul> <li>RNN(Recurrent Neural Network) 은 순환 신경망이라 불리고 은닉층 노드의 출력값을 출력층과 그 다음 시점의 은닉층 노드의 입력으로 전달해 순환하는 특징을 지니고 있다.</li> <li>일반적으로 RNN에서는 (a) 형태를 세워놓은 (b) 표현법을 많이 사용한다.</li> <li>RNN 모델에서 x는 입력 벡터, y는 출력 벡터, t는 현재 시점을 의미한다. <ul> <li>즉, x_t는 현재 시점의 입력 벡터, y_t는 현재 시점의 출력 벡터를 의미한다.</li> </ul> </li> <li>RNN에서 은닉층 노드는 <em>이전 시점(t − 1)의 상태값을 저장하는 메모리 역할</em>을 수행하기 때문에 <strong>셀(cell) 또는 메모리 셀</strong>이라고 한다.</li> <li><em>은닉층의 메모리 셀의 출력 벡터는 출력층과 다음 시점(t + 1)의 메모리 셀에 전달</em>되는데 이를 <strong>은닉 상태(Hidden State)</strong> 라고 한다. <ul> <li>또한 h_t는 현재 시점의 은닉 상태, h_(t + 1)은 다음 시점의 은닉 상태를 의미한다.</li> </ul> </li> </ul> <p><img src="https://user-images.githubusercontent.com/28593767/115508866-be943c00-a2b8-11eb-8531-d32637da1036.png" alt="rnn2"/></p> <ul> <li>RNN 모델을 <em>시점의 흐름에 따라 표현한 그림으로 현재 시점의 메모리 셀은 이전 시점의 은닉 상태값에 영향을 받고 있으며 완전 연결 계층 구조를 가지고 있다</em>는 점을 알 수 있다.</li> <li>RNN 모델은 어떤 문제를 해결하느냐에 따라 입력과 출력의 길이를 조절할 수 있다.</li> </ul> <h4 id="many-to-one-rnn">Many-to-One RNN</h4> <p><img src="https://user-images.githubusercontent.com/28593767/115508868-bf2cd280-a2b8-11eb-8c63-7ecbde19e7dd.png" alt="m-o"/></p> <ul> <li>many-to-one은 여러 개를 입력받아 하나를 출력하는 모델을 의미한다.</li> <li>다이어그램은 09:00 부터 09:59 분 까지 온도 데이터를 입력받아 현재까지의 온도 흐름이 정상인지 비정상인지 판단한다.</li> </ul> <h4 id="one-to-many-rnn">One-to-Many RNN</h4> <p><img src="https://user-images.githubusercontent.com/28593767/115508870-c05dff80-a2b8-11eb-9bcd-d030c43b09a1.png" alt="o-m"/></p> <ul> <li>one-to-many는 하나를 입력받아 여러 개를 출력하는 모델을 의미한다.</li> <li>다이어그램은 한 장의 이미지를 입력받아 이미지를 설명하는 텍스트를 출력하는 모델로 사용할 수 있다.</li> </ul> <h4 id="many-to-many-rnn">Many-to-Many RNN</h4> <p><img src="https://user-images.githubusercontent.com/28593767/115508873-c05dff80-a2b8-11eb-848d-0ad92c11353d.png" alt="m-m"/></p> <ul> <li>many-to-many는 여러 개를 입력으로 받아 여러 개를 출력하는 모델을 의미한다.</li> <li>개체명 인식기에서도 사용하는 모델로 <strong>단어 시퀀스를 입력으로 받아 각 시퀀스가 의미하는 개체명을 출력하는 구조</strong>이다.</li> <li>한국어를 입력으로 받아 영어로 출력하는 번역기 모델로도 사용 가능하다.</li> </ul> <h2 id="rnn의-원리">RNN의 원리</h2> <p><img src="https://user-images.githubusercontent.com/28593767/115508875-c0f69600-a2b8-11eb-9454-f5e47e3ca70a.png" alt="rnn3"/></p> <ul> <li>RNN은 모든 시점에서 동일한 가중치와 편향값을 사용한다.</li> <li>현재 시점을 t로 정의할 때 각 변수는 다음과 같다. <ul> <li>x_t는 현재 시점의 입력 벡터</li> <li>y_t는 현재 시점의 출력 벡터</li> <li>h_t는 현재 시점의 은닉 상태 벡터값</li> </ul> </li> <li>RNN의 각 노드에 연결되어 있는 가중치는 다음과 같다. <ul> <li>w_x는 입력 x_t에 대한 가중치</li> <li>w_h는 이전 시점의 은닉 상태값인 h_(t - 1)에 대한 가중치</li> <li>w_y는 현재 시점의 은닉 상태값인 h_t에 대한 가중치</li> </ul> </li> <li><img src="https://user-images.githubusercontent.com/28593767/115508877-c18f2c80-a2b8-11eb-9333-5200e20ffd39.png" alt="rnn4"/></li> <li>현재 시점의 은닉 상탯값 h_t 는 현재 입력값 x_t와 이전 시점의 은닉 상태값 h_(t - 1)으로 계산하고 활성화 함수로 <strong>하이퍼볼릭 탄젠트(tanh)</strong> 를 사용한다.</li> <li><em>이전 시점의 은닉 상탯값이 현재 시점의 은닉 상태에 계속해서 영향을 주기 때문에 시퀀스 데이터의 특징을 잘 파악</em>할 수 있다.</li> <li>출력층 y_t는 메모리 셀에서 계산된 은닉 상태값 h_t와 가중치 w_y를 곱한 값으로 계산한다.</li> </ul> <h3 id="simplernn">SimpleRNN</h3> <p><img src="https://user-images.githubusercontent.com/28593767/115508869-bfc56900-a2b8-11eb-9413-e4eb49ff038a.png" alt="rnn5"/></p> <ul> <li>SimpleRNN 레이어는 가장 간단한 형태의 RNN 레이어이다.</li> <li>순환 신경망은 변화하는 입력을 받기 때문에 각 단계에서 입력이 변할 때의 계산의 흐름을 보여준다.</li> <li>SimpleRNN 레이어에는 <em>입력 데이터가 길어질수록, 즉 데이터의 타임스텝이 커질 수록 학습 능력이 떨어진다</em>는 <strong>장기 의존성(Long-Term Dependency)</strong> 문제가 있다. <ul> <li>즉, 입력 데이터와 출력 사이의 길이가 멀어질수록 연관관계가 적어진다.</li> </ul> </li> <li>SimpleRNN 레이어는 같은 가중치 W를 반복적으로 사용해서 출력값을 계산하는데 같은 값을 계속 곱하게 되면 값이 엄청나게 커지는 <strong>그레이언트 폭발(Gradient Exploding)</strong> 이나 <strong>그레디언트 소실(Gradient Vanishing)</strong> 문제가 발생할 수 있다. <ul> <li>과거의 정보를 통해 현재의 답을 구하는 RNN이지만 과거 시점이 현재에서 너무 멀어지면 문제를 풀기 어렵다는 말과 같다.</li> <li>이러한 RNN의 장기 의존성 문제를 해결하기 위해 LSTM이 제안되었다.</li> </ul> </li> <li>또한 활성화 함수를 tanh 대신 ReLU를 사용하면 학습 자체가 불안정해진다.</li> </ul> <p><img width="493" alt="rnn_1" src="https://user-images.githubusercontent.com/28593767/115660170-9703a900-a376-11eb-939e-7f7d6a94cf06.png"/></p> <p><img width="337" alt="rnn_2" src="https://user-images.githubusercontent.com/28593767/115660168-9539e580-a376-11eb-8f32-0d418e38dfeb.png"/></p> <h2 id="장단기-메모리-long-short-term-memory">장단기 메모리 Long Short Term Memory</h2> <p><img width="1118" alt="lstm" src="https://user-images.githubusercontent.com/28593767/115660171-979c3f80-a376-11eb-8920-ae071d4f2303.png"/></p> <ul> <li>LSTM은 RNN에 비해 복잡한 구조를 가지고 있는데 특히 출력 외에 LSTM 셀 사이에서만 공유되는 <strong>셀 상태(Cell State)</strong> 를 가지고 있다는 특징이 있다. <ul> <li>c_(t − 1)과 c_t가 셀 상태를 나타내는 기호이다.</li> </ul> </li> <li>SimpleRNN 셀에서 타임스텝의 방향으로 h_t만 전달되지만 LSTM 셀에서는 셀 상태인 c_t가 평행선을 그리며 함께 전달된다.</li> <li>즉, <em>타임스텝을 가로지르며 셀 상태가 보존되기 때문에 장기 의존성 문제를 해결</em>할 수 있다. <ul> <li>과거의 정보 중 sigmoid 함수를 통해 몇 퍼센트만 기억시킨다.</li> </ul> </li> <li>결과적으로 LSTM은 <strong>잊을건 잊고 기억할 것은 기억하며 성능을 높이는 모델</strong>이라고 할 수 있다.</li> </ul> <p><img width="1256" alt="lstm2" src="https://user-images.githubusercontent.com/28593767/115660174-98cd6c80-a376-11eb-9ebd-00041a66898e.png"/></p> <ul> <li>U와 W는 입력과 출력에 곱해지는 가중치이다.</li> <li><em>수식 1, 2, 3</em>은 각각 타임스텝 t에서의 Input, Forget, Output 게이트를 통과한 출력을 의미한다.</li> <li><em>수식 4</em>는 x_t와 h_(t - 1)을 가중치 U와 W에 곱한 뒤 tanh 활성화 함수를 취한 값으로 셀 상태인 c_t가 되기 전의 출력값이다.</li> <li><em>수식 5, 6</em>은 셀 상태와 LSTM의 출력을 계산하는 가장 중요한 부분이다. <ul> <li>셀 상태는 Forget 게이트의 출력에 의해 이전 타임스템의 셀 상태를 얼마만큼 남길지 결정되고 새로 입력된 Input 게이트의 출력과 <em>수식 4</em>를 곱한 값을 더해서 다음 타임스텝의 셀 상태를 만든다.</li> </ul> </li> <li>LSTM 참고 링크: <a href="https://dgkim5360.tistory.com/entry/understanding-long-short-term-memory-lstm-kr">LSTM 이해하기</a></li> <li><strong>Gate Recurrent Units(GRU)</strong> 은 게이트 메커니즘이 적용된 RNN 프레임워크로 LSTM의 영감을 받아 고안된 더 간략한 구조로 만들어진 모델이다.</li> </ul> <h2 id="양방향-lstm-bi-lstm">양방향 LSTM Bi-LSTM</h2> <ul> <li>RNN이나 LSTM은 일반 신경망과 다르게 <em>시퀀스 또는 시계열 데이터 처리에 특화되어 은닉층에서 과거의 정보를 기억</em>할 수 있지만 순환 신경망의 구조적 특성상 <em>데이터가 입력 순으로 처리되기 때문에 이전 시점의 정보만 활용할 수 밖에 없다는 단점</em>이 존재한다. <ul> <li>즉, 문장이 길어질수록 성능이 저하될 수 밖에 없다.</li> </ul> </li> </ul> <p><img src="https://user-images.githubusercontent.com/28593767/115667678-14341b80-a381-11eb-858b-02a0776d4500.png" alt="ex"/></p> <ul> <li>RNN이나 LSTM에서는 <em>ios와 앱</em>이라는 단어만 가지고 빈칸에 들어갈 <em>개발</em>이라는 단어를 유추하기엔 정보가 매우 부족하다.</li> <li>예문에서는 문장의 앞부분보다 뒷 부분에 중요한 정보가 존재한다.</li> <li>따라서 <em>자연어 처리에 있어 입력 데이터의 정방향 처리만큼 역방향 처리도 중요</em>하다고 할 수 있다.</li> </ul> <p><img src="https://user-images.githubusercontent.com/28593767/115667683-15654880-a381-11eb-9192-6a5bcefed9dc.png" alt="bi-lstm"/></p> <ul> <li><strong>양방향 LSTM(Bidirectional LSTM)</strong> 은 <em>기존 LSTM 계층에 역방향으로 처리하는 LSTM 계층을 하나 더 추가해 양방향에서 문장의 패턴을 분석할 수 있도록 구성</em>되어 있다. <ul> <li>입력 문장을 양방향에서 처리하므로 <em>시퀀스 길이가 길어진다 하더라도 정보손실없이 처리가 가능</em>하다.</li> </ul> </li> <li>정방향 LSTM은 기존과 동일하게 입력 문장을 왼쪽에서 오른쪽으로 처리하며 역방향 LSTM은 입력 문장의 단어 순서를 반대로 처리한다.</li> </ul>]]></content><author><name></name></author><category term="bootcamp"/><category term="study"/><category term="note"/><summary type="html"><![CDATA[순환 신경망 Recurrent Neural Network]]></summary></entry><entry><title type="html">convolutional neural network</title><link href="https://wonkwonlee.github.io/blog/2021/convolutional-neural-network/" rel="alternate" type="text/html" title="convolutional neural network"/><published>2021-04-14T00:00:00+00:00</published><updated>2021-04-14T00:00:00+00:00</updated><id>https://wonkwonlee.github.io/blog/2021/convolutional-neural-network</id><content type="html" xml:base="https://wonkwonlee.github.io/blog/2021/convolutional-neural-network/"><![CDATA[<h1 id="합성곱-신경망-convolutional-neural-network">합성곱 신경망 Convolutional Neural Network</h1> <h2 id="cnn이란">CNN이란</h2> <p><img width="1105" alt="cnn" src="https://user-images.githubusercontent.com/28593767/114647239-b9167f00-9d17-11eb-85e4-63c3384a14ec.png"/></p> <ul> <li>합성곱 신경망은 인간의 시각 체계처럼 이미지를 인식하는 신경망으로 이미지가 입력값인 분류 문제를 잘 다룬다.</li> <li>CNN에서는 <strong>컨볼루션 층(Convolutional Layers)</strong>, <strong>풀링 층(Pooling Layers)</strong>, <strong>완전 연결 계층</strong>이 등장한다. <ul> <li><em>이미지는 각 픽셀이 인접한 픽셀과 강한 연관성</em>이 있기 때문에 <em>컨볼루션 층에서는 출력값이 입력값의 일부로부터만 영향을 받는 국소성(Local Connectivity)이 강한 처리가 수행</em>된다.</li> <li><em>풀링 층은 인식하는 대상의 위치를 유연하게 처리할 수 있는 구조</em>로 구성되어 있다.</li> </ul> </li> </ul> <h2 id="cnn의-구조">CNN의 구조</h2> <ul> <li>합성곱 신경망은 이미치 처리에 알맞게 다층 퍼셉트론을 변형시킨 신경망으로 이미지 처리에 알맞게 고안된 합성곱 계층과 풀링 계층이 새로운 유형의 은닉 계층으로 이용된다.</li> <li>합성곱 계층은 다층 퍼셉트론의 완전 연결 계층에 비해 획기적으로 줄어든 수의 파라미터만을 가지며 풀링 계층은 아예 파라미터를 갖지 않는다. <ul> <li>다층 퍼셉트론 신경망의 은닉 계층은 완전 연결 계층이기 때문에 많은 수의 픽셀로 구성된 이미지 데이터의 경우 입력 벡터 크기가 커지면서 완전 연결 계층의 가중치 파라미터가 엄청난 크기를 갖게 된다.</li> <li>메모리 부담도 문제지만 많은 파라미터 탓에 학습이 느려지기 쉬우며 지나치게 많은 양의 데이터가 필요할 수 있다.</li> </ul> </li> <li>합성곱 신경망은 합성곱 계층이 갖는 <em>소수의 파라미터를 집중적으로 학습 시키는 방법으로 이미지 처리 분야에서의 학습 품질을 크게 향상</em>시켰다.</li> </ul> <p><img width="957" alt="cnn2" src="https://user-images.githubusercontent.com/28593767/114647247-bcaa0600-9d17-11eb-87fc-50126ad9eb44.png"/></p> <ul> <li>CNN에는 컨볼루션 층, 풀링 층, 완전 연결 계층의 3개 층이 있다. <ul> <li>이미지는 컨볼루션 층으로 입력되고 컨볼루션 층과 풀링 층은 몇 번 반복된 후 완전 연결 계층으로 연결된다.</li> <li>완전 연결 계층도 몇 번 반복되고 최종 완전 연결 계층은 출력층이 된다.</li> </ul> </li> <li>컨볼루션 층에서는 <em>입력되는 이미지에 여러 개의 필터 처리가 적용되어 입력된 이미지는 필터 처리 후에 이미지의 특징을 나타내는 여러 개의 이미지로 변환</em>된다.</li> <li>풀링 층에서는 이미지의 특징을 잃어버리지 않도록 <em>이미지 크기가 축소</em>된다.</li> <li>완전 연결 계층에서는 층 간의 모든 뉴런이 연결되어 있다.</li> </ul> <h3 id="컨볼루션-층-convolutional-layers">컨볼루션 층 Convolutional Layers</h3> <p><img width="1274" alt="convolution" src="https://user-images.githubusercontent.com/28593767/114647375-f7ac3980-9d17-11eb-87bd-25c67be91ff4.png"/></p> <ul> <li>컨볼루션(합성곱)은 이미지 처리 분야에서 매우 일반적인 연산으로 이미지의 특징을 강화하거나 약화시킨다. <ul> <li>컨볼루션 층은 이 컨볼루션 연산을 통해 입력 이미지의 특징을 더 강조한 이미지로 변환한다.</li> </ul> </li> <li>이미지에는 각 픽셀이 인접하는 픽셀과 강한 관련성을 갖고 있는 성질이 있는데 이를 <strong>국소성(Locality)</strong> 혹은 집약성이라고 한다.</li> <li><em>컨볼루션 층은 이러한 이미지의 국소성을 이용해 이미지의 특징을 검출</em>한다.</li> </ul> <p><img width="1287" alt="conv2" src="https://user-images.githubusercontent.com/28593767/114647379-f8dd6680-9d17-11eb-80c1-ed24b99a5494.png"/></p> <ul> <li>일반적인 이미지 데이터는 각 픽셀이 RGB의 3색, 즉 3개의 채널을 갖고 있다.</li> <li>CNN은 여러 개의 채널을 가진 이미지에 대해 여러 개의 채널을 이용한 컨볼루션을 적용한다.</li> <li>각 필터는 입력 이미지와 같은 채널 수를 갖기 때문에, 예를 들어 입력 이미지가 RGB이면 각 필터에는 3개의 채널 수가 필요하다.</li> <li>컨볼루션에 의해 생성된 이미지의 각 픽셀에는 편향을 더해 활성화 함수에서 처리한다. <ul> <li>편향은 하나의 필터당 하나의 값을 설정하고 따라서 필터의 수와 편향의 수가 같다.</li> </ul> </li> </ul> <p><img width="830" alt="conv_full" src="https://user-images.githubusercontent.com/28593767/114647382-f975fd00-9d17-11eb-85de-6aa395e43b6f.png"/></p> <ul> <li>컨볼루션 층은 필터마다 처리를 수행하기 때문에 완전 연결 계층과 비교해 층 간의 접속이 국소적이다.</li> <li>즉, 시각 영역과 같이 국소적인 특징을 파악하는 데 적합한 신경망 구조라고 할 수 있다.</li> <li>필터를 적용한 이미지 영역은 1차 시각 영역에서 단순형 세포의 수용 영역에 해당한다.</li> </ul> <h3 id="풀링-층-pooling-layers">풀링 층 Pooling Layers</h3> <p><img width="578" alt="pooling" src="https://user-images.githubusercontent.com/28593767/114647571-478b0080-9d18-11eb-9287-3519dc9ddb93.png"/></p> <ul> <li>풀링 층은 보통 <em>컨볼루션층 바로 뒤에 배치되어 이미지를 여러 영역으로 구획하고 각 영역을 대표하는 값을 추출해 새로운 이미지</em>를 만드는데 이와 같은 처리를 <strong>풀링(Pooling)</strong> 이라고 한다.</li> <li>일반적으로 풀링은 <em>각 영역의 최댓값을 영역의 대표값으로 설정</em>하는데 이와 같은 풀링 방법을 <strong>맥스 풀링</strong>이라고 한다. <ul> <li>영역의 평균 값을 선택하는 평균 풀링 등의 방법도 있지만 CNN에서는 맥스 풀링이 많이 사용된다.</li> </ul> </li> <li>풀링 처리를 하면 이미지가 축소되고 이미지를 흐릿하게 처리하기 때문에 대상의 위치 감도가 저하된다. <ul> <li>풀링은 위치의 변화에 대해 강건성을 부여한다.</li> <li>또한 풀링을 통해 이미지의 크기가 축소되기 때문에 계산량이 감소하는 효과도 있다.</li> <li>풀링 층에서 <em>구획되는 영역은 고정되어 있고 학습하는 파라미터가 없으므로 학습이 진행되지 않고 채널이 합류되거나 분기되는 것도 없기 때문에 입력 채널 수와 출력 채널 수는 동일</em>하다.</li> </ul> </li> </ul> <h3 id="완전-연결-계층-fully-connected-layers">완전 연결 계층 Fully-Connected Layers</h3> <ul> <li>완전 연결 계층은 일반적인 신경망에서 이용되는 층으로 컨볼루션층과 풀링층이 몇 번 반복된 후 배치된다.</li> <li>컨볼루션 층과 풀링 층에서 추출된 특징량에 기반해 계산이 수행되고 결과를 출력한다.</li> <li>완전 연결 계층 사이의 연결에서는 일반적인 신경망과 마찬가지로 뉴런이 서로 이웃하는 층의 모든 뉴런과 연결된다. <ul> <li>컨볼루션 층과 풀링 층의 출력을 완전 연결 계층으로 입력할 경우 이미지를 벡터로 변환한다.</li> <li>예를 들어 출력 이미지의 높이가 H, 너비가 W, 채널 수가 F이면 완전 연결 계층의 입력은 크기가 H * W * F인 벡터가 된다.</li> </ul> </li> </ul> <h3 id="패딩-padding">패딩 Padding</h3> <p><img width="1275" alt="padding" src="https://user-images.githubusercontent.com/28593767/114647577-4954c400-9d18-11eb-96e0-930701b32ca7.png"/></p> <ul> <li>컨볼루션 층과 풀링 층에서 <em>입력 이미지를 둘러싸는 것처럼 픽셀을 배치하는 기법</em>을 패딩이라고 한다.</li> <li>이미지의 주위에 값이 0인 픽셀을 배치하는 방법을 <strong>제로 패딩(Zero Padding)</strong> 이라고 한다.</li> <li>컨볼루션 층이나 풀링 층을 거치면 이미지 크기가 축소되지만 패딩을 적용하면 컨볼루션 처리를 거쳐도 이미지 크기가 변하지 않을 수 있다.</li> <li>또한 컨볼루션의 특성 상 이미지의 가장자리는 컨볼루션 적용 횟수가 적어지지만 패딩을 적용하면 가장자리 데이터에 적용되는 컨볼루션 횟수를 증가시켜 가장자리 부분의 특징도 포함시키는 장점이 있다.</li> </ul> <h3 id="스트라이드-stride">스트라이드 Stride</h3> <ul> <li>스트라이드는 <em>컨볼루션에서 필터가 이동하는 간격</em>을 의미한다.</li> <li>스트라이드가 커지면 필터의 이동 간격도 커지기 때문에 생성되는 이미지의 크기가 작아진다.</li> <li>매우 큰 이미지를 축소시키기 위해 스트라이드를 사용하기도 하지만 특징을 잘 포착하지 못할 우려가 있어 보통은 스트라이드를 1로 설정하는 편이 바람직하다.</li> </ul> <h3 id="cnn의-학습">CNN의 학습</h3> <ul> <li>CNN 역시 일반적인 신경망과 같이 역전파를 통해 학습이 수행된다.</li> <li>컨볼루션 층에서는 필터가 학습에 의해 최적화된다.</li> <li>출력값과 정답의 오차로부터 전파되어 온 값을 이용해 필터를 구성하는 각 값의 기울기를 계산하고 필터가 수정된다.</li> <li>편향 또한 같은 과정으로 수정되고 오차는 컨볼루션 층을 통해 더 앞 층으로 전파된다.</li> <li>완전 연결 계층에서는 일반적인 신경망과 같은 방법으로 오차의 전파가 진행된다.</li> </ul> <p><img width="543" alt="train" src="https://user-images.githubusercontent.com/28593767/114647580-4a85f100-9d18-11eb-9159-a797ccebf5a7.png"/></p> <h3 id="채널-channel">채널 Channel</h3> <p><img width="827" alt="channel" src="https://user-images.githubusercontent.com/28593767/114651160-62607380-9d1e-11eb-8899-668b17547ce1.png"/></p> <ul> <li>합성곱 연산에서 <em>커널은 입력 영역의 특정 패턴이나 특징에 민감하게 반응하는 방향으로 학습되는 경향</em>이 있고 따라서 합성곱 계층에서 출력되는 픽셀 이미지를 <strong>특징맵(Feature Map)</strong> 이라고 한다.</li> <li>CNN이 다루는 이미지 데이터에는 가로와 세로 해상도 외에 <strong>채널(Channel)</strong> 이라는 차원이 추가된다.</li> <li>합성곱 계층의 입력 채널 수는 최초의 입력 이미지 혹은 이전 계층이 생성한 출력 채널 수로 정해지지만, 출력 채널 수는 신경망 설계자가 마음대로 정할 수 있다. <ul> <li>일반적으로 합성곱 신경망을 설계할 때는 합성곱 계층의 출력 채널 수를 입력 채널 수보다 늘려 더 많은 종류의 특징을 파악할 수 있게 한다.</li> <li>이렇게 합성곱 계층을 거칠 때마다 늘어난 정보량은 합성곱 계층 사이에 배치된 풀링 계층을 통해 다시 줄어든다.</li> </ul> </li> <li>풀링 층을 거친 이미지는 대개 해상도가 줄어들기만 할 뿐 채널 수는 변하지 않고 그대로 유지된다.</li> </ul> <h3 id="커널-kernel">커널 Kernel</h3> <p><img width="446" alt="kernel" src="https://user-images.githubusercontent.com/28593767/114651157-6096b000-9d1e-11eb-8ac8-60d01957c7de.png"/></p> <ul> <li>이미지의 작은 사각 영역에서 하나의 특징을 온전히 포착하려면 커널은 <em>해당 영역의 모든 채널에 대한 입력 픽셀값을 볼 수 있어야 한다</em>.</li> <li>하나의 특징을 포착하는 커널은 <em>사각 영역 입력의 모든 채널을 처리하는 3차원 가중치</em>를 가져야 한다.</li> <li>또한 출력 채널 수 만큼의 특징 맵을 만들어 내기 위해 커널이 출력 채널 수 만큼 있어야 한다.</li> <li>따라서 커널은 입력 영역 크기에 <em>입력 채널과 출력 채널이 모두 반영된 4차원 구조</em>가 되어야 한다.</li> </ul> <p><img width="638" alt="channel2" src="https://user-images.githubusercontent.com/28593767/114651561-2f6aaf80-9d1f-11eb-895c-0819c717851f.png"/></p>]]></content><author><name></name></author><category term="bootcamp"/><category term="study"/><category term="note"/><summary type="html"><![CDATA[합성곱 신경망 Convolutional Neural Network]]></summary></entry><entry><title type="html">adaptive moments estimation</title><link href="https://wonkwonlee.github.io/blog/2021/adaptive-moments-estimation/" rel="alternate" type="text/html" title="adaptive moments estimation"/><published>2021-04-12T00:00:00+00:00</published><updated>2021-04-12T00:00:00+00:00</updated><id>https://wonkwonlee.github.io/blog/2021/adaptive-moments-estimation</id><content type="html" xml:base="https://wonkwonlee.github.io/blog/2021/adaptive-moments-estimation/"><![CDATA[<h1 id="adam-알고리즘-adaptive-moments-estimation">ADAM 알고리즘 Adaptive Moments Estimation</h1> <h2 id="딥러닝에서의-다차원-분류-및-adam-알고리즘">딥러닝에서의 다차원 분류 및 Adam 알고리즘</h2> <p><img width="500" alt="office31" src="https://user-images.githubusercontent.com/28593767/114334392-745ade80-9b85-11eb-81da-011bd93430cf.png"/></p> <ul> <li><em>두 가지 차원에서 동시에 분류를 수행하는 다차원 분류 신경망</em>에 Adam 알고리즘을 적용하여 신경망 모델의 학습 품질을 향상시킨다.</li> <li>office31 데이터셋은 컴퓨터 비전 분야에서의 전이학습 연구용으로 구축된 표준 벤치마크 데이터셋으로 수집 방법에 따른 3가지 도메인과 31가지 사무용품 이미지 4,652장으로 구성되어 있다.</li> <li>즉, 한 장의 사진은 31가지 사무용품 중 어떠한 품목에 속하는지, 그리고 어떠한 도메인에서 수집이 되었는지 이중으로 레이블링 되어 있다.</li> </ul> <h3 id="전이-학습-transfer-learning">전이 학습 Transfer Learning</h3> <ul> <li>전이학습은 <em>한 도메인에서 학습시킨 결과를 다른 도메인에서 활용하여 학습 효과를 높이는 학습 기법</em>을 말한다.</li> <li>예를 들어 amazon 도메인에 속한 데이터들에 품목 레이블 정보가 모두 태깅되어 있어서 이를 이용해 학습을 시켜 높은 성능을 발휘하는 모델이 있다고 가정할 때, 이미 확보된 amazon 도메인 모델의 학습 정보를 잘 활용하면 품목 레이블 정보가 매우 적거나 없는 webcam 도메인에서 그나마 나은 성능을 확보할 수 있다.</li> <li>즉, <strong>학습에 필요한 데이터의 부족 현상을 해결하고자 연구 되어지는 분야</strong>가 바로 전이 학습이다.</li> </ul> <h3 id="다차원-분류-multi-dimensional-classification">다차원 분류 Multi-Dimensional Classification</h3> <ul> <li>이미지를 넣었을 때 도메인과 품목을 동시에 판별해 주는 딥러닝 모델을 만든다고 한다면 도메인과 품목, 즉 <em>두 가지 차원에서의 분류를 한 번에 수행하고 결과 또한 동시에 보여줘야 하기에 난이도가 높다.</em></li> <li><strong>차원 축소(Dimensionality Reduction)</strong> 이란 <em>복합 출력에 대한 학습 방식으로 2차원 분류를 1차원으로 줄이는 방법</em>이다.</li> <li>딥러닝에서는 같은 퍼셉트론이라도 어떠한 학습 과정을 거치냐에 따라 역할이 달라지게 된다. <ul> <li>달라지는 것은 가중치나 편향 같은 파라미터 값의 구성이며, 똑같은 퍼셉트론이라도 학습시키기에 따라 전복의 고리 수를 추정할 수도 있고 꽃 이미지를 구분할 수도 있다.</li> </ul> </li> <li>즉, <strong>동일한 구조의 신경망을 다양한 용도에 이용하기 위해서는 후처리 과정의 처리 방법만 변경</strong> 하면 된다.</li> <li>이러한 후처리 과정은 <strong>후처리 순전파</strong> 과정과 <strong>후처리 역전파</strong> 과정으로 구성되어 있다. <ul> <li>후처리 순전파 과정은 <em>신경망 순전파 처리 과정에서 얻어진 출력으로 부터 손실 함수를 계산하는 과정</em>을 의미한다.</li> <li>후처리 역전파 과정은 <em>출력에 따른 각 성분들의 손실 기울기를 계산해서 신경망 역전파 처리 과정에 도움을 주는 과정</em>을 의미한다.</li> </ul> </li> </ul> <p><img width="567" alt="IO" src="https://user-images.githubusercontent.com/28593767/114334399-77ee6580-9b85-11eb-9571-ada347e4b2a2.png"/></p> <ul> <li>office31 데이터셋을 이용한 다차원 분류의 경우 신경망은 <em>이미지 픽셀 수 만큼의 입력 벡터 크기</em>를 가지며 <em>출력 벡터 크기는 도메인 판별에 사용될 성분 3가지와 품목 판별에 사용될 성분 31 가지를 더한 34가지 성분</em>을 가진다.</li> <li>만약 필요한 출력별로 별도의 신경망을 구성한다면 어떻게 될까? <ul> <li>출력 계층을 구성하는 퍼셉트론은 맡은 임무에 따라 역할이 확실하게 다르기 때문에 출력 계층만 따지면 신경망을 분리하든 말든 별 차이가 없다.</li> <li>하지만 <em>은닉 계층에 속한 퍼셉트론은 모든 출력 계층 퍼셉트론에 영향</em>을 주고 <em>모든 출력 계층 퍼셉트론으로 부터 역전파 피드백</em>을 받으므로 복합 출력으로 처리하는 경우와 신경망을 따로 구성하는 경우에 커다란 차이가 발생한다.</li> <li>따라서 각각의 출력을 위한 별도의 은닉 계층을 힘들게 따로 학습시키는 것보다 <strong>모든 출력에 연결된 하나의 은닉 계층이 이러한 공통 특성을 포착하도록 학습시키면 계산량을 절감하면서도 성능을 향상 시킬 수 있다.</strong></li> </ul> </li> <li>결론적으로 출력에 따라 별도의 신경망을 구성하는 것보다는 <em>하나의 신경망 출력을 복합 출력으로 처리하는 방법이 더 바람직하다.</em></li> </ul> <h3 id="복합-출력의-학습-방법">복합 출력의 학습 방법</h3> <p><img width="622" alt="MDC" src="https://user-images.githubusercontent.com/28593767/114334402-7886fc00-9b85-11eb-92bb-1aa76076c17f.png"/></p> <ul> <li>하나의 신경망이 두 성분으로 구성되는 복합 출력을 낼 때의 학습 방법은 비교적 간단하다.</li> <li>레이블 정보로 준비된 정답 <em>y1, y2</em> 와 복합 출력의 두 성분 <em>output1, output2</em> 를 비교해 손실값 <em>L1, L2</em> 를 얻을 때, 전체적인 손실 함수값을 <em>L = L1 + L2</em>로 정의하면 된다.</li> <li>다른 변수의 영향을 받지 않는 편미분의 특성 상 <em>L1</em>과 <em>L2</em>는 서로에게 상수로 취급되기 때문에 <em>output1</em> 의 손실 기울기는 <em>y1</em>과의 후처리 과정을 통해 <em>L1</em>을 이용해 구하면 되고 <em>output2</em>의 손실 기울기는 <em>y2</em>와의 후처리 과정을 통해 <em>L2</em>를 이용해 구하면 된다.</li> <li>즉, <strong>기존의 방법 그대로를 적용해 두 부분의 손실 기울기를 따로 구하면 된다</strong>.</li> <li>구해진 손실 기울기는 <em>두 부분으로 갈라진 출력 계층에 따로 반영</em>되지만 <em>은닉 계층 퍼셉트론에 이르러서는 인접한 계층 간의 완전 연결 탓에 마구 뒤섞여 반영</em>된다.</li> </ul> <h2 id="adam-최적화-기법-adam-optimizer">ADAM 최적화 기법 ADAM Optimizer</h2> <p><a href="https://arxiv.org/pdf/1609.04747.pdf"><strong>An overview of gradient descent optimization algorithms</strong></a></p> <p><a href="https://arxiv.org/pdf/1412.6980.pdf"><strong>ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION</strong></a></p> <h3 id="확률적-경사-하강법-stochastic-gradient-descent">확률적 경사 하강법 Stochastic Gradient Descent</h3> <p><img width="283" alt="sgd" src="https://user-images.githubusercontent.com/28593767/114334407-791f9280-9b85-11eb-82e5-635c078e5147.png"/></p> <ul> <li>기존의 경사 하강법에서 특정 데이터만을 샘플링하여 학습하는 <strong>확률적 경사 하강법(SGD)</strong> 은 심층 신경망(DNN) 을 학습시키기위해 주로 이용되고 있는 최적화 기법이다.</li> <li>심층 신경망을 더 효율적으로 학습시키기 위해서 다양한 SGD의 변형이 제시되고 있는데, 이러한 SGD의 변형은 크게 두 가지로 나눠 볼 수 있다. <ul> <li><img width="548" alt="sgd2" src="https://user-images.githubusercontent.com/28593767/114334408-791f9280-9b85-11eb-88a2-bff434714e5c.png"/></li> <li>첫 번째는 <strong>momentum</strong> 이라는 개념을 이용하여 gradient를 수정하는 알고리즘이고 두 번째는 자동으로 learning rate를 조절하는 알고리즘이다.</li> </ul> </li> </ul> <h3 id="momentum">Momentum</h3> <p><img width="273" alt="momentum" src="https://user-images.githubusercontent.com/28593767/114334409-79b82900-9b85-11eb-962a-5caf5dd4def2.png"/></p> <ul> <li>기존의 SGD는 현재 시간의 gradient만을 이용해서 파라미터를 업데이트했지만, 반면 모멘텀 기반의 SGD는 이전 시간의 gradient까지 고려하여 파라미터를 업데이트한다.</li> <li>이 식에서 𝛽 ∈ [0,1]은 일반적으로 0.9로 설정되는 하이퍼파라미터로서 이전 gradient와 현재의 gradient 간의 영향력을 조절하는 역할을 수행한다.</li> <li>모멘텀은 현재 시간의 gradient가 가장 높은 중요도를 갖고 이전 시간의 gradient는 두 번째로 높은 중요도를 갖는 방식으로 이전 시간의 모든 gradient를 고려하여 방향을 설정하도록 한다.</li> <li>모멘텀의 장점은 이전의 SGD 보다 더 빠르게 최적점으로 찾아갈 수 있다는 점과 지역 최적값(Local Minimum) 을 회피할 수 있다는 것이다. <ul> <li>다만, 모멘텀을 이용한다 해서 무조건 빠져나갈 수 있다는 보장은 하지 못한다.</li> </ul> </li> </ul> <h3 id="adaptive-gradient-adagrad">Adaptive Gradient (AdaGrad)</h3> <p><img width="755" alt="adagrad" src="https://user-images.githubusercontent.com/28593767/114334410-79b82900-9b85-11eb-995c-8b3cadf81d76.png"/></p> <ul> <li>AdaGrad는 최적화 과정을 효율적으로 만들기 위해 <strong>고정된 learning rate가 아닌, 각각의 변수마다 적합한 learning rate를 자동으로 설정</strong>하는 알고리즘이다.</li> <li><em>변화가 많았던 변수들은 최적점이 근처에 있을 확률이 높다 판단하여 learning rate값을 낮춰 더욱 세밀하게 갱신</em>되도록 만든다.</li> <li>반면 <em>변화가 적었던 변수들은 최적점에서 멀리 벗어나 있을 확률이 높기 때문에 learning rate값을 크게 함으로써 더욱 빠르게 최적점으로 수렴</em>하게 만든다.</li> <li>ε은 일반적으로 10e−8과 같은 매우 작은 상수로 0으로 나눠지는 것을 방지하기 위해 추가된다.</li> <li>AdaGrad의 장점은 learning rate decay와 같은 방법들을 이용하여 <em>학습률을 직접적으로 조절하지 않아도 된다는 점</em>과 모든 변수에 일괄적으로 동일한 학습률을 적용하는 기존의 SGD 기반 알고리즘과는 달리 <em>적합한 학습률을 자동으로 설정한다는 것</em>이다.</li> <li>AdaGrad의 문제점은 학습률을 조절하는 <em>g_ij</em>은 어떠한 값을 제곱한 것이 계속 더해지기 때문에 시간이 지날수록 증가하고, 이에 따라 학습률 또한 시간에 따라 감소하여 어느 정도 지난 뒤에는 학습률이 매우 작아져 가중치가 갱신되지 않는다는 점이다.</li> </ul> <h3 id="root-mean-square-propagation-rmsprop">Root Mean Square Propagation (RMSprop)</h3> <p><img width="397" alt="rmsprop" src="https://user-images.githubusercontent.com/28593767/114340241-1a144a80-9b92-11eb-98cb-ea9e7b385709.png"/></p> <p><img width="397" alt="rmsprop_w" src="https://user-images.githubusercontent.com/28593767/114340240-197bb400-9b92-11eb-8f90-e2453a6d5ff8.png"/></p> <ul> <li>RMSprop는 학습이 진행될수록 분모에 위치하고 있는 gradient 제곱의 합인 <em>g_ij</em>의 값이 커짐으로써 학습률이 극단적으로 감소하는 AdaGrad의 문제점을 해결하기 위해 제안된 알고리즘이다.</li> <li>RMSprop에서는 <em>g_ij</em>를 gradient 제곱의 합이 아니라 gradient 제곱의 지수 이동 평균으로 정의한다. <ul> <li>지수 이동 평균은 최근 값을 더 잘 반영하기 위해 최근의 변화량에 더 높은 가중치를 주어 계산하는 방식을 의미한다.</li> </ul> </li> <li>𝛽의 값은 Momentum과 마찬가지로 0과 1 사이의 값을 갖지만 일반적으로 0.9의 값으로 설정되고 ε은 일반적으로 10e−8과 같은 매우 작은 수로 설정한다.</li> <li>이전의 AdaGrad는 현재 시간까지의 변화량의 합으로 정의되기 때문에 시간이 지날수록 증가하여 학습률이 급격하게 감소하였지만, RMSprop에서는 지수 이동 평균으로 인해 현재의 <em>g_ij</em> 가 급격하게 감소하는 현상을 방지할 수 있다.</li> </ul> <h3 id="adaptive-momentum-estimation-adam">Adaptive Momentum Estimation (Adam)</h3> <p><img width="765" alt="adam" src="https://user-images.githubusercontent.com/28593767/114340237-18e31d80-9b92-11eb-996a-3f84ea1e3ca2.png"/></p> <ul> <li>Adam은 딥러닝 학습에 가장 광범위하게 이용되고 있는 알고리즘으로 경험적 근거에 의하여 가장 좋은 학습 성능을 보여준 최적화 기법이다.</li> <li>앞서 살펴보았던 두 개의 알고리즘인 Momemtum과 RMSprop를 합친 것 같은 알고리즘이라고 할 수 있다.</li> <li>수식을 통해 살펴보면 <em>g_ij</em>를 통해 학습률을 조절하는 RMSprop의 방식이 눈에 들어오지만, <em>v</em>를 구하는 과정에서는 Momentum의 방식이 쓰인다.</li> <li><em>g</em>와 <em>v</em>는 지수 이동 평균으로 구해지고 𝛽1, 𝛽2 은 0과 1 사이의 값을 갖지만 일반적으로 0.9, 0.999로 설정된다.</li> <li>Adam에서는 v_ij와 g_ij 값을 그대로 이용하지 않는다. <ul> <li>논문에 의하면 두 값에 대한 초기값을 0 벡터로 주면, 학습 초기에 가중치들이 0으로 편향 되는 경향을 보이고 특히 decay rate가 작으면 즉 𝛽1 ,𝛽2 가 1에 가까워지면 편향은 더 심해진다고 한다.</li> <li><img width="719" alt="adam2" src="https://user-images.githubusercontent.com/28593767/114340231-1680c380-9b92-11eb-90a4-924301e95940.png"/></li> </ul> </li> </ul>]]></content><author><name></name></author><category term="bootcamp"/><category term="study"/><category term="note"/><summary type="html"><![CDATA[ADAM 알고리즘 Adaptive Moments Estimation]]></summary></entry><entry><title type="html">linear algebra</title><link href="https://wonkwonlee.github.io/blog/2021/linear-algebra/" rel="alternate" type="text/html" title="linear algebra"/><published>2021-04-12T00:00:00+00:00</published><updated>2021-04-12T00:00:00+00:00</updated><id>https://wonkwonlee.github.io/blog/2021/linear-algebra</id><content type="html" xml:base="https://wonkwonlee.github.io/blog/2021/linear-algebra/"><![CDATA[<h1 id="선형대수학-linear-algebra">선형대수학 Linear Algebra</h1> <h2 id="벡터와-스칼라-vector-and-scalar">벡터와 스칼라 Vector and Scalar</h2> <ul> <li>수학에서는 데이터 여러 개를 한 줄에 담아낼 수 있게 만든 것을 벡터라고 한다. <ul> <li>프로그래밍에서도 여러 개의 데이터를 하나의 열에 담아 둔 것을 벡터 또는 배열이라고 한다.</li> </ul> </li> <li>벡터의 표기 : <strong>a, b</strong></li> <li>벡터의 덧셈은 서로 대응하는 성분끼리 덧셈을 한다.</li> </ul> <h3 id="단어의-벡터화-word2vec">단어의 벡터화 word2vec</h3> <ul> <li><em>단어들을 마치 벡터처럼 취급</em>하여 일반적인 벡터 연산처럼 단어들 간의 연산이 가능해진다.</li> <li><a href="https://arxiv.org/pdf/1301.3781.pdf"><strong>word2vec</strong></a>은 단어를 벡터처럼 다르는 방법으로 2013년 구글이 발표한 기법이다.</li> <li>또한 2016년 페이스북에서 fastText라고 하는 <em>언어를 벡터로 표현하는 기법</em> 또한 제안되었다.</li> </ul> <h3 id="유향선분-directed-segment">유향선분 Directed Segment</h3> <ul> <li>벡터는 <strong>방향</strong>과 <strong>거리</strong>의 두가지 요소를 지니고 있다. 이러한 방향과 거리를 나타내는 화살표를 <strong>유향선분</strong>이라고 한다.</li> <li>벡터의 연산의 그래프</li> </ul> <p><img src="https://user-images.githubusercontent.com/28593767/111561402-b89dcd80-87d7-11eb-8b43-6afdba1c5427.png" alt="vec"/></p> <h2 id="내적-inner-product">내적 Inner product</h2> <p><img src="https://user-images.githubusercontent.com/28593767/111561405-b9cefa80-87d7-11eb-9a12-f61756107c0a.png" alt="dot1"/></p> <p><img src="https://user-images.githubusercontent.com/28593767/111561409-ba679100-87d7-11eb-88dc-ac0a67012776.png" alt="dot2"/></p> <ul> <li>내적의 계산은 벡터끼리 서로 대응하는 성분끼리 곱한 다음 그것을 모두 더한 값을 의미하고 &lt;<strong>a, b</strong>&gt; 라고 표기한다.</li> <li>다른 말로 점곱(Dot product)라고도 한다.</li> <li><strong>벡터와 벡터를 내적한 결과는 벡터가 아니라 스칼라</strong>가 되고 <strong>서로 다른 차원의 벡터끼리는 계산을 할 수 없다</strong>.</li> </ul> <p><img width="400" alt="orthogonal" src="https://user-images.githubusercontent.com/28593767/111566301-41b90280-87e0-11eb-9e3f-9aa78f13642d.png"/></p> <ul> <li>두 개의 벡터가 <strong>a, b</strong>가 서로 <strong>직교한다</strong>는 것은 두 벡터가 이루는 각이 90°라는 의미이다.</li> <li>두 벡터가 직교할 때 내적 &lt;<strong>a, b</strong>&gt; = 0 이다.</li> <li>다시 말해, 두 벡터가 직교하는지 확인하려면 <strong>두 벡터의 내적이 0인지 확인</strong>하면 된다.</li> </ul> <h2 id="노름-norm">노름 Norm</h2> <ul> <li>벡터의 이동 거리를 노름이라고 한다.</li> <li> <p>맨하튼 거리 Manhattan distance(L1 노름) : 가로와 세로의 바둑판 모양을 따라 움직이는 방법이다.</p> <p><img src="https://user-images.githubusercontent.com/28593767/111561396-b76ca080-87d7-11eb-8c17-f4249853690d.png" alt="norm1"/></p> <ul> <li>벡터 각 성분들의 절댓값을 구한 다음, 모두 더하면 된다.</li> </ul> </li> <li> <p>유클리드 거리 Euclidean distance(L2 노름) : 시작점부터 목적지까지 직선으로 움직이는 방법이다.</p> <p><img src="https://user-images.githubusercontent.com/28593767/111561478-db2fe680-87d7-11eb-93ef-5e62fd067ad4.png" alt="norm2"/></p> <ul> <li>피타고라스 정리를 이용해서 구하면 된다.</li> </ul> </li> </ul> <h3 id="인공지능에서의-활용">인공지능에서의 활용</h3> <ul> <li>L1 노름과 L2 노름은 선형회귀 모델의 정규화 항에서 사용할 수 있다.</li> <li><strong>overfitting</strong> 현상이 발생할 시, 선형회귀 모델에 정규화 항을 덧붙여 계수의 절댓값이나 제곱한 값이 너무 커지지 않도록 만들어 줘야 한다.</li> <li>즉, <strong>정규화 항은 계수가 너무 커지지 않게 하기 위한 일정의 패널티나 핸디캡같은 억제 기능</strong>을 한다.</li> </ul> <h2 id="코사인-유사도-cosine-similarity">코사인 유사도 Cosine Similarity</h2> <p><img src="https://user-images.githubusercontent.com/28593767/111565970-ac1d7300-87df-11eb-92bc-7b16346392da.png" alt="cos"/></p> <ul> <li>코사인 유사도는 내적의 정의식과 L2 노름의 정의식을 활용하여 구할 수 있고 cos(<strong>a, b</strong>)로 표현한다.</li> <li>코사인 유사도의 값은 −1≤ cos(<strong>a, b</strong>) ≤ 1 의 구간 안에 있다.</li> <li>유사도가 -1 일 때는 두 벡터가 서로 <em>반대 방향으로 평행</em>이고, 0 일 때는 <em>직교 상태</em>, 그리고 1일 때는 서로 <em>같은 방향으로 평행</em>이 된다.</li> <li>다시 말해, <strong>코사인 유사도가 더 높다는 말은 벡터가 더 닮았다</strong>는 의미라고 할 수 있다.</li> </ul> <h3 id="인공지능에서의-활용-1">인공지능에서의 활용</h3> <ul> <li>AI가 텍스트를 분석할 때는 단어나 문장을 벡터로 처리하는데 이 때 벡터로 만들어진 단어나 문장들은 서로의 관계성을 파악할 때 코사인 유사도를 사용한다.</li> <li>즉, 코사인 유사도가 높을수록 해당 단어나 문장들은 더 가까운 관계라고 할 수 있다.</li> </ul> <h2 id="행렬-matrix">행렬 Matrix</h2> <ul> <li>행렬은 복잡한 계산을 간단한 형태로 표현할 때 사용한다.</li> <li>행렬은 같은 차원의 벡터를 여러 개 쌓아놓은 것과 같다.</li> <li>행렬을 더하거나 뺄 때는 서로 대응하는 성분끼리 덧셈, 뺄셈을 한다.</li> <li><strong>행렬의 곱셈은 곧 벡터의 내적을 확장한 것</strong>이라 할 수 있다. <ul> <li><img src="https://user-images.githubusercontent.com/28593767/111565977-ad4ea000-87df-11eb-8d92-dbc5410c055d.png" alt="matrix"/></li> <li>(m * n) 행렬과 (n * l) 행렬을 곱하면 그 결과는 (m * l) 행렬이 된다.</li> <li>행렬의 곱셈에서는 <em>AB = BA</em> 같은 <strong>교환법칙이 성립하지 않는다</strong>.</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="bootcamp"/><category term="study"/><category term="note"/><summary type="html"><![CDATA[선형대수학 Linear Algebra]]></summary></entry><entry><title type="html">shortest path algorithm</title><link href="https://wonkwonlee.github.io/blog/2021/shortest-path-algorithm/" rel="alternate" type="text/html" title="shortest path algorithm"/><published>2021-04-08T00:00:00+00:00</published><updated>2021-04-08T00:00:00+00:00</updated><id>https://wonkwonlee.github.io/blog/2021/shortest-path-algorithm</id><content type="html" xml:base="https://wonkwonlee.github.io/blog/2021/shortest-path-algorithm/"><![CDATA[<h1 id="최단-경로-알고리즘-shortest-path-algorithm">최단 경로 알고리즘 Shortest Path Algorithm</h1> <h2 id="최단-경로-문제-shortest-path-problem">최단 경로 문제 Shortest Path Problem</h2> <ul> <li><em>최단 경로 알고리즘은 가장 짧은 경로를 찾는 알고리즘</em>으로 <strong>길 찾기 문제</strong>라고도 불린다.</li> <li>최단 경로 알고리즘 유형에는 다양한 종류가 있고 상황에 맞는 효율적인 알고리즘이 이미 정립되어 있다. <ul> <li>예를 들어, <em>한 지점에서 다른 특징 지점까지의 최단 경로를 구해야 하는 경우</em> 혹은 <em>모든 지점에서 다른 모든 지점까지의 최단 경로를 모두 구해야 하는 경우</em> 등 다양한 사례가 존재한다.</li> <li>대표적인 최단 경로 알고리즘에는 <strong>다익스트라(Dijkstra Algorithm), 플로이드 워셜(Floyd-Warshall Algorithm), 벨만 포드 알고리즘(Bellman-Ford Algorithm)</strong> 등이 있다.</li> </ul> </li> <li>최단 경로 문제는 보통 그래프를 이용해 표현하는데 각 지점은 그래프에서 <strong>노드(node)</strong> 로 표현되고 지점간 연결된 도로는 그래프에서 <strong>간선(edge)</strong> 로 표현한다.</li> <li>실제 코딩 테스트에서는 최단 경로를 모두 출력하는 문제보다는 <em>단순히 최단 거리를 출력하도록 요구하는 문제가 많이 출제</em>된다. <ul> <li>그리디 알고리즘 및 다이나믹 프로그래밍 알고리즘이 최단 경로 알고리즘에 그대로 적용된다.</li> </ul> </li> </ul> <h2 id="다익스트라-알고리즘-dijkstra-algorithm">다익스트라 알고리즘 Dijkstra Algorithm</h2> <ul> <li>다익스트라 최단 경로 알고리즘은 그래프에서 여러 개의 노드가 있을 때 <strong>특정한 노드에서 출발하여 다른 노드로 가는 각각의 최단 경로</strong>를 구해 주는 알고리즘이다.</li> <li>다익스트라 최단 경로 알고리즘은 <strong>음의 간선</strong>이 없을 때 정상적으로 동작한다. <ul> <li>음의 간선이란 0보다 작은 값을 가지는 간선을 의미한다.</li> <li>현실 세계의 길은 음의 간선으로 표현되지 않으므로 <em>다익스트라 알고리즘은 실제로 GPS 소프트웨어의 기본 알고리즘으로 채택</em>된다.</li> </ul> </li> <li>다익스트라는 매번 <em>가장 비용이 적은 노드를 선택해서 임의의 과정을 반복</em>하기 때문에 기본적으로 그리디 알고리즘으로 분류된다.</li> </ul> <h3 id="다익스트라-알고리즘의-작동-원리">다익스트라 알고리즘의 작동 원리</h3> <ol> <li><strong>출발 노드</strong>를 설정한다.</li> <li>최단 거리 테이블을 초기화 한다.</li> <li>방문하지 않은 노드 중에서 <strong>최단 거리가 가장 짧은 노드를 선택</strong>한다.</li> <li>해당 노드를 거쳐 다른 노드로 가는 비용을 계산하여 <strong>최단 거리 테이블을 갱신</strong>한다.</li> <li>위의 과정에서 3, 4번을 반복한다.</li> </ol> <ul> <li>다익스트라 알고리즘은 <strong>각 노드에 대한 현재까지의 최단 거리</strong> 정보를 항상 1차원 리스트에 저장하며 리스트를 계속 갱신한다.</li> <li>다시 말해, 현재 처리하고 있는 노드를 기준으로 주변 간선을 확인하고 나중에 더 짧은 경로를 찾으면 갱신한다.</li> </ul> <p><img width="498" alt="spp" src="https://user-images.githubusercontent.com/28593767/113644114-ef705080-96be-11eb-9d08-2d1c7173deb2.png"/></p> <blockquote> <p>출발 노드를 1이라고 할 때, 1번 노드에서 다른 모든 노드로의 최단 거리를 계산한다.</p> <p>초기 상태에서는 <em>다른 모든 노드로 가는 최단 거리를 무한으로 초기화</em>한다.</p> </blockquote> <p><img width="689" alt="dijk0" src="https://user-images.githubusercontent.com/28593767/113794762-442ace80-9786-11eb-91d2-ffbccaac29b9.png"/></p> <p><img width="413" alt="d0" src="https://user-images.githubusercontent.com/28593767/113794998-d337e680-9786-11eb-9be1-9e8e1a322080.png"/></p> <p><img width="689" alt="dijk1" src="https://user-images.githubusercontent.com/28593767/113794768-45f49200-9786-11eb-9dd2-b956771cd5b7.png"/></p> <p><img width="413" alt="d1" src="https://user-images.githubusercontent.com/28593767/113795000-d3d07d00-9786-11eb-9c15-e11c586812ef.png"/></p> <p><img width="689" alt="dijk2" src="https://user-images.githubusercontent.com/28593767/113794769-468d2880-9786-11eb-9104-3c6e444f8599.png"/></p> <p><img width="413" alt="d2" src="https://user-images.githubusercontent.com/28593767/113795003-d4691380-9786-11eb-91b2-576aea1f0055.png"/></p> <p><img width="689" alt="dijk3" src="https://user-images.githubusercontent.com/28593767/113794772-47be5580-9786-11eb-9042-cdf3e2bfb32d.png"/></p> <p><img width="413" alt="d3" src="https://user-images.githubusercontent.com/28593767/113795006-d501aa00-9786-11eb-8cf8-0275f3f1024d.png"/></p> <p><img width="689" alt="dijk4" src="https://user-images.githubusercontent.com/28593767/113794773-47be5580-9786-11eb-8aae-f809240d97ab.png"/></p> <p><img width="413" alt="d4" src="https://user-images.githubusercontent.com/28593767/113795007-d501aa00-9786-11eb-82b9-de5d7a1219c5.png"/></p> <p><img width="689" alt="dijk5" src="https://user-images.githubusercontent.com/28593767/113794766-455bfb80-9786-11eb-869e-c9a4c6aa9c1c.png"/></p> <p><img width="413" alt="d5" src="https://user-images.githubusercontent.com/28593767/113794995-d0d58c80-9786-11eb-93c0-d4e33c68141b.png"/></p> <p><img width="689" alt="dijk6" src="https://user-images.githubusercontent.com/28593767/113794771-4725bf00-9786-11eb-9dbf-b81777f5fb4e.png"/></p> <p><img width="413" alt="d6" src="https://user-images.githubusercontent.com/28593767/113794997-d206b980-9786-11eb-9491-c8d4de03eebc.png"/></p> <h3 id="간단한-다익스트라-알고리즘">간단한 다익스트라 알고리즘</h3> <ul> <li>다익스트라에 의해 처음 고안된 알고리즘으로 직관적이고 이해하기 쉽다.</li> <li>V는 노드의 개수를 의미하고 각 노드에 대한 최단 거리를 담는 1차원 리스트를 선언한다.</li> <li><strong>각 단계마다 방문하지 않은 노드 중에서 최단 거리가 가장 짧은 노드를 선택하기 위해 매 단계마다 1차원 리스트의 모든 원소를 순차 탐색으로 확인</strong>한다.</li> <li>모든 리스트는 <strong>(노드의 개수 + 1)의 크기로 할당하여 노드의 번호를 인덱스</strong>로 하여 바로 리스트에 접근한다.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">sys</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">sys</span><span class="p">.</span><span class="n">stdin</span><span class="p">.</span><span class="n">readline</span>
<span class="n">INF</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="mf">1e9</span><span class="p">)</span>

<span class="c1"># N is the number of node and M is the number of edge
</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nf">input</span><span class="p">().</span><span class="nf">split</span><span class="p">())</span>
<span class="c1"># Starting node position
</span><span class="n">start</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="nf">input</span><span class="p">())</span>
<span class="n">graph</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>

<span class="c1"># Initialize all node to be unvisited
</span><span class="n">visited</span> <span class="o">=</span> <span class="p">[</span><span class="bp">False</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># Initialize current distance to be infinity
</span><span class="n">distance</span> <span class="o">=</span> <span class="p">[</span><span class="n">INF</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="nf">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="nf">input</span><span class="p">().</span><span class="nf">split</span><span class="p">())</span>
    <span class="c1"># For each node index, store edge to the neighboring node
</span>    <span class="n">graph</span><span class="p">[</span><span class="n">a</span><span class="p">].</span><span class="nf">append</span><span class="p">((</span><span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">get_smallest_node</span><span class="p">():</span>
    <span class="n">min_value</span> <span class="o">=</span> <span class="n">INF</span>
    <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">distance</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">min_value</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">visited</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span> 
            <span class="n">min_value</span> <span class="o">=</span> <span class="n">distance</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">i</span>

    <span class="k">return</span> <span class="n">index</span>


<span class="k">def</span> <span class="nf">dijkstra</span><span class="p">(</span><span class="n">start</span><span class="p">):</span>
    <span class="n">distance</span><span class="p">[</span><span class="n">start</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">visited</span><span class="p">[</span><span class="n">start</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">graph</span><span class="p">[</span><span class="n">start</span><span class="p">]:</span>
        <span class="n">distance</span><span class="p">[</span><span class="n">j</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">j</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">now</span> <span class="o">=</span> <span class="nf">get_smallest_node</span><span class="p">()</span>
        <span class="n">visited</span><span class="p">[</span><span class="n">now</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">graph</span><span class="p">[</span><span class="n">now</span><span class="p">]:</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="n">distance</span><span class="p">[</span><span class="n">now</span><span class="p">]</span> <span class="o">+</span> <span class="n">j</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> 
            <span class="k">if</span> <span class="n">cost</span> <span class="o">&lt;</span> <span class="n">distance</span><span class="p">[</span><span class="n">j</span><span class="p">[</span><span class="mi">0</span><span class="p">]]:</span> 
                <span class="n">distance</span><span class="p">[</span><span class="n">j</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">cost</span>


<span class="nf">dijkstra</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">distance</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">INF</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">INFINITY</span><span class="sh">"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">distance</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

<span class="sh">'''</span><span class="s">
INPUT
6 11
1
1 2 2; 1 3 5; 1 4 1; 2 3 3; 2 4 2; 3 2 3; 3 6 5; 4 3 3; 4 5 1; 5 3 1; 5 6 2

OUTPUT
0; 2; 3; 1; 2; 4
</span><span class="sh">'''</span>
</code></pre></div></div> <h2 id="플로이드-워셜-알고리즘-floyd-warshall-algorithm">플로이드 워셜 알고리즘 Floyd-Warshall Algorithm</h2> <ul> <li>플로이드 워셜 알고리즘은 <strong>모든 지점에서 다른 모든 지점까지의 최단 경로를 모두 구해야 하는 경우</strong>에 사용할 수 있는 알고리즘이다. <ul> <li>그에 비해, 다익스트라 알고리즘은 <em>한 지점에서 다른 특정까지의 최단 경로를 구해야 하는 경우</em>에 사용한다.</li> </ul> </li> <li>플로이드 워셜은 단계마다 거쳐 가는 노드를 기준으로 알고리즘을 수행한다. <ul> <li>하지만 다익스트라 알고리즘과 달리 <em>매번 방문하지 않은 노드 중에서 최단 거리를 갖는 노드를 찾을 필요가 없다.</em></li> </ul> </li> <li>노드의 개수 N개에 대해 각 노드마다 <em>O(N^2)</em> 의 연산을 통해 현재 노드를 거쳐가는 모든 경로를 고려하기 때문에 플로이드 워셜의 총 시간 복잡도는 <strong><em>O(N^3)</em></strong>가 된다.</li> <li>모든 노드에 대하여 다른 모드 노드로 가는 최단 거리 정보를 담아야 하기 때문에 <em>2차원 리스트에 최단 거리 정보를 저장</em>한다.</li> <li>플로이드 워셜은 노드의 개수가 N이라고 할 때, N 번 만큼의 단계를 반복하며 <em>점화식에 맞게</em> 2차원 리스트를 갱신한다. <ul> <li>따라서 플로이드 워셜은 그리디 알고리즘이 아니다.</li> </ul> </li> </ul> <h3 id="플로이드-워셜-알고리즘의-작동-원리">플로이드 워셜 알고리즘의 작동 원리</h3> <p><img src="https://user-images.githubusercontent.com/28593767/113955671-2aa58780-9857-11eb-91aa-777c214c0e2e.png" alt="fw"/></p> <ul> <li>플로이드 알고리즘은 현재 확인하고 있는 노드를 제외하고, N-1 개의 노드 중에서 서로 다른 노드 (A,B) 쌍을 선택하고 이후 A → 1 번 노드 → B로 가는 비용을 확인한 뒤에 최단 거리를 갱신한다.</li> <li>점화식을 풀어보면 <strong>A에서 B로 가는 최소 비용(D_ab)과 A에서 K를 거쳐 B로 가는 비용(D_ak + D_kb) 을 비교하여 더 작은 값으로 갱신</strong>한다는 의미이다.</li> <li>즉, <em>바로 이동하는 거리가 특정한 노드를 거쳐서 이동하는 거리보다 더 많은 비용을 가진다면 이를 더 짧은 것으로</em> 갱신한다.</li> </ul> <h4 id="step-0-초기-테이블-설정">Step 0: 초기 테이블 설정</h4> <p><img src="https://user-images.githubusercontent.com/28593767/113955677-2c6f4b00-9857-11eb-8aff-475d2a6d6810.png" alt="step0"/></p> <h4 id="step-1-1번-노드를-거쳐-가는-경우">Step 1: 1번 노드를 거쳐 가는 경우</h4> <p><img src="https://user-images.githubusercontent.com/28593767/113955678-2d07e180-9857-11eb-89c0-5fbd669b9be5.png" alt="step1"/></p> <h4 id="step-2-2번-노드를-거쳐-가는-경우">Step 2: 2번 노드를 거쳐 가는 경우</h4> <p><img src="https://user-images.githubusercontent.com/28593767/113955681-2e390e80-9857-11eb-8bbe-7212b34cd807.png" alt="step2"/></p> <h4 id="step-3-3번-노드를-거쳐-가는-경우">Step 3: 3번 노드를 거쳐 가는 경우</h4> <p><img src="https://user-images.githubusercontent.com/28593767/113955682-2ed1a500-9857-11eb-8864-c97d228e14ce.png" alt="step3"/></p> <h4 id="step-4-4번-노드를-거쳐-가는-경우">Step 4: 4번 노드를 거쳐 가는 경우</h4> <p><img src="https://user-images.githubusercontent.com/28593767/113955683-2f6a3b80-9857-11eb-8af0-2fec8dcc51b3.png" alt="step4"/></p> <h4 id="모든-노드의-최단-거리-테이블">모든 노드의 최단 거리 테이블</h4> <p><img src="https://user-images.githubusercontent.com/28593767/113956423-62f99580-9858-11eb-9a9a-5d8ee1f0e9a8.png" alt="step_final"/></p> <blockquote> <p>예를 들어 D_13의 값은 8인데, 이는 1번 노드에서 3번 노드로 가는 최단 거리가 8이라는 의미이다.</p> </blockquote>]]></content><author><name></name></author><category term="bootcamp"/><category term="study"/><category term="note"/><summary type="html"><![CDATA[최단 경로 알고리즘 Shortest Path Algorithm]]></summary></entry></feed>